{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modelling on Research Papers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNlgnrvXpjXM6V+fsY1kcll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Degananda264/Topic-Modelling-on-Research-Papers/blob/master/Topic_Modelling_on_Research_Papers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAh1-VZD68VM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c68016cd-cfb4-44c3-a41d-168487905338"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: nvidia-sim: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgA0x0kJcaq8",
        "colab_type": "text"
      },
      "source": [
        "**Download Data and Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJIeT4ACcGj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5ef4192c-3f37-4490-ddff-1b77487a54db"
      },
      "source": [
        "!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
        "!tar -xzf nips12raw_str602.tgz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-16 14:20:13--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12851423 (12M) [application/x-gzip]\n",
            "Saving to: ‘nips12raw_str602.tgz’\n",
            "\n",
            "\rnips12raw_str602.tg   0%[                    ]       0  --.-KB/s               \rnips12raw_str602.tg  11%[=>                  ]   1.41M  7.07MB/s               \rnips12raw_str602.tg  58%[==========>         ]   7.12M  17.8MB/s               \rnips12raw_str602.tg  98%[==================> ]  12.09M  20.1MB/s               \rnips12raw_str602.tg 100%[===================>]  12.26M  20.2MB/s    in 0.6s    \n",
            "\n",
            "2020-07-16 14:20:13 (20.2 MB/s) - ‘nips12raw_str602.tgz’ saved [12851423/12851423]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caAY0nLEciix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "bb3b2a80-8c7f-474b-93c8-e0433ba11b17"
      },
      "source": [
        "!pip install tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfWlV1r4c6t3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ac7b2cbb-e45a-4427-f50c-46c98673c851"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = 'nipstxt/'\n",
        "print(os.listdir(DATA_PATH))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['idx', 'orig', 'nips11', 'nips02', 'nips07', 'nips12', 'README_yann', 'nips06', 'nips01', 'nips09', 'nips03', 'nips05', 'nips00', 'nips10', 'nips08', 'RAW_DATA_NOTES', 'nips04', 'MATLAB_NOTES']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIeghWLZdiBB",
        "colab_type": "text"
      },
      "source": [
        "**Load NIPS Research Papers Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVW7ydYTdLbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "547319f2-f944-4a41-c840-8fe0daf995ab"
      },
      "source": [
        "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
        "# Read all texts into a list.\n",
        "papers = []\n",
        "for folder in folders:\n",
        "    file_names = os.listdir(DATA_PATH + folder)\n",
        "    for file_name in file_names:\n",
        "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
        "            data = f.read()\n",
        "        papers.append(data)\n",
        "len(papers)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1740"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1f5jjBXdps_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "0f4a1f2f-a59b-4abb-d940-6e8290acc713"
      },
      "source": [
        "papers[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'27O \\nCorrelational Strength and Computational Algebra \\nof Synaptic Connections Between Neurons \\nEberhard E. Fetz \\nDepartment of Physiology & Biophysics, \\nUniversity of Washington, Seattle, WA 98195 \\nABSTRACT \\nIntracellular recordings in spinal cord motoneurons and cerebral \\ncortex neurons have provided new evidence on the correlational strength of \\nmonosynaptic connections, and the relation between the shapes of \\npostsynaptic potentials and the associated increased firing probability. In \\nthese cells, excitatory postsynaptic potentials (EPSPs) produce cross- \\ncorrelogram peaks which resemble in large part the derivative of the EPSP. \\nAdditional synaptic noise broadens the peak, but the peak area -- i.e., the \\nnumber of above-chance firings triggered per EPSP -- remains proportional to \\nthe EPSP amplitude. A typical EPSP of 100 gv triggers about .01 firings per \\nEPSP. The consequences of these data for information processing by \\npolysynaptic connections is discussed. The effects of sequential polysynaptic \\nlinks can be calculated by convolving the effects of the underlying \\nmonosynaptic connections. The net effect of parallel pathways is the sum of \\nthe individual contributions. \\nINTRODUCTION \\nInteractions between neurons are determined by the strength and \\ndistribution of their synaptic connections. The strength of synaptic \\ninteractions has been measured directly in the central nervous system by two \\ntechniques. Intracellular recording reveals the magnitude and time course of \\npostsynaptic potentials (PSPs) produced by synaptic connections, and cross- \\ncorrelation of extracellular spike trains measures the effect of the PSP\\'s on the \\nfiring probability of the connected cells. The relation between the shape of \\nexcitatory postsynaptic potentials (EPSPs) and the shape of the cross- \\ncorrelogram peak they produce has been empirically investigated in cat \\nmotoneurons 2,4,5 and in neocortical cells 10. \\nRELATION BETWEEN EPSP\\'S AND CORRELOGRAM PEAKS \\nSynaptic interactions have been studied most thoroughly in spinal \\ncord motoneurons. Figure I illustrates the membrane potential of a \\nrhythmically firing motoneuron, and the effect of EPSPs on its firing. An \\nEPSP occurring sufficiently close to threshold () will cause the motoneuron \\nto fire and will advance an action potential to its rising edge (top). \\nMathematical analysis of this threshold-crossing process predicts that an \\nEPSP with shape e(t) will produce a firing probability f(t), which resembles \\n American Institute of Phys. ics 1988 \\n271 \\nEPSP \\nCROSS- \\nCORRELOGRAM \\nf(t) \\nTIME \\'1- \\nFig. 1. The relation between EPSP\\'s and motoneuron firing. Top: membrane trajectory of \\nrhythmically firing motoneuron, showing EPSP crossing threshold (O) and shortening the \\nnormal interspike interval by advancing a spike. V(t) is difference between membrane \\npotential and threshold. Middle: same threshold-crossing process aligned with EPSP, with \\nv(t) plotted as falling trajectory. Intercept (at upward arrow) indicates time of the advanced \\naction potential. Bottom: Cross-correlation histogram predicted by threshold crossings. The \\npeak in the firing rate fit) above baseline (fo) is produced by spikes advanced from baseline, \\nas indicated by the changed counts for the illustrated trajectory. Consequently, the area in \\nthe peak equals the area of the subsequent trough. \\n272 \\nthe derivative of the EPSP 4,8. Specifically, for smooth membrane potential \\ntrajectories approaching threshold (the case of no additional synaptic noise): \\nf(t) = fo + fro/:g) de/dt \\n(1) \\nwhere fo is the baseline firing rate of the motoneuron and \\x7f\\' is the rate of \\nclosure between motoneuron membrane potential and threshold. This \\nrelation can be derived analytically by tranforming the process to a \\ncoordinate system aligned with the EPSP (Fig. 1, middle) and calculating the \\nrelative timing of spikes advanced by intercepts of the threshold trajectories \\nwith the EPSP 4. The above relation (1) is also valid for the correlogram \\ntrough during the falling ph. ase of the EPSP, as long as de/dt > -{\\'; if the EPSP \\nfalls more rapidly than -v, the trough is limited at zero firing rate (as \\nillustrated for the correlogram at bottom). The fact that the shape of the \\ncorrelogram peak above baseline matches the EPSP derivative has been \\nempirically confirmed for large E?S?s in cat motoneurons 4. This relation \\nimplies that the height of the correlogram peak above baseline is proportional \\nto the EPS? rate of rise. The integral of this relationship predicts that the area \\nbetween the correlogram peak and baseline is proportional to the EPSP \\namplitude. This linear relation further implies that the effects of \\nsimultaneously arriving EPSPs will add linearly. \\nThe presence of additional background synaptic \"noise\", which is \\nnormally produced by randomly occurring synaptic inputs, tends to make the \\ncorrelogram peak broader than the duration of the EPSP risetime. This \\nbroadening is produced by membrane potential fluctuations which cause \\nadditional threshold crossings during the decay of the EPSP by trajectories \\nthat would have missed the EPSP (e.g., the dashed trajectory in Fig. 1, \\nmiddle). On the basis of indirect empirical comparisons it has been proposed \\n6,7 that the broader correlogram peaks can be described by the sum of two \\nlinear functions of e(t): \\nf(t) = fo + a e(t) + b de/dt \\n(2) \\nThis relation provides a reasonable match when the coefficients (a and b) can \\nbe optimized for each case 5,7, but direct empirical comparisons 2,4 indicate \\nthat the difference between the correlogram peak and the derivative is \\ntypically briefer than the EPSP. \\nThe effect of synaptic noise on the transform \\'between EPSP and \\ncorrelogram peak has not yet been analytically derived (except for the case of \\nGaussian noisel). However the threshold-crossing process has been \\nsimulated by a computer model which adds synaptic noise to the trajectories \\nintercepting the EPSP 1. The correlograms generated by the simulation match \\nthe correlograms measured empirically for small EPS?\\'s in motoneurons 2, \\nconfirming the validity of the model. \\nAlthough synaptic noise distributes the triggered firings over a wider \\npeak, the area of the correlogram peak, i.e., the number of motoneuron firings \\nproduced by an EPSP, is essentially preserved and remains proportional to \\nEPSP amplitude for moderate noise levels. For unitary EPSP\\'s (produced by \\n273 \\na single afferent fiber) in cat motoneurons, the number of firings triggered per \\nEPSP (Np) was linearly related to the amplitude (h) of the EPSP 2: \\nNp = (0.1/mv)o h (mv) + .003 \\n(3) \\nThe fact that the number of triggered spikes increases in proportion to E?S? \\namplitude has also been confirmed for neocortical neurons 10; for cells \\nrecorded in sensorimotor cortex slices (probably pyramidal cells) the \\ncoefficient of h was very similar: 0.07/rev. This means that a typical unitary \\nEPSP with amplitude of 100 gv, raises the probability that the postsynaptic \\ncell fires by less than .01. Moreover, this increase occurs during a specific \\ntime interval corresponding to the rise time of the EPS? - on the order of 1 - 2 \\nmsec. The net increase in firing rate of the postsynaptic cell is calculated by \\nthe proportional decrease in interspike intervals produced by the triggered \\nspikes 4. (While the above values are typical, unitary EPSP\\'s range in size \\nfrom several hundred gv down to undetectable levels of several gv., and \\nhave risetimes of .2 - 4 msec.) \\nInhibitory connections between cells, mediated by inhibitory \\npostsynaptic potentials (IPSPs), produce a trough in the cross-correlogram. \\nThis reduction of firing probability below baseline is followed by a \\nsubsequent broad, shallow peak, representing the spikes that have been \\ndelayed during the IPSP. Although the effects of inhibitory connections \\nremain to be analyzed more quantitatively, preliminary results indicate that \\nsmall IPSP\\'s in synaptic noise produce decreases in firing probability that are \\nsimilar to the increases produced by EPS?\\'s 4,5. \\nDISYNAPTIC LINKS \\nThe effects of polysynaptic links between neurons can be understood \\nas combinations of the underlying monosynaptic connections. A \\nmonosynaptic connection from cell A to cell B would produce a first-order \\ncross-correlation peak Pi(B[A,t), representing the conditional probability that \\nneuron B fires above chance at time t, given a spike in cell A at time t = 0. As \\nnoted above, the shape of this first-order correlogram peak is largely \\nproportional to the E?S? derivative (for cells whose interspike interval \\nexceeds the duration of the EPSP). The latency of the peak is the conduction \\ntime from A to B (Fig. 2 top left). \\nIn contrast, several types of disynaptic linkages between A and B, \\nmediated by a third neuron C, will produce a second-order correlation peak \\nbetween A and B. A disynaptic link may be produced by two serial \\nmonosynaptic connections, from A to C and from C to B (Fig. 2, bottom left), \\nor by a common synaptic input from C ending on both A and B (Fig. 2, \\nbottom right). In both cases, the second-order correlation between A and B \\nproduced by the disynaptic link would be the convolution of the two first- \\norder correlations between the monosynaptically connected cells: \\nP2(BIA) = P\\x7f(BIC) OP\\x7f(CIA) (4) \\n274 \\nAs indicated by the diagram, the cross-correlogram peak P2(BIA,t) would be \\nsmaller and more dispersed than the peaks of the underlying first-order \\ncorrelation peaks. For serial connections the peak would appear to the right \\nof the origin, at a latency that is the sum of the two monosynaptic latencies. \\nThe peak produced by a common input typically straddles the origin, since its \\ntiming reflects the difference between the underlying latencies. \\nMonosynaptic connection --> First-order correlation \\n. : \\x7f(AIB,t) = P\\x7f(BIA,-t) \\n: \\x7f\\x7f(B ,A, t) \\n , \\nDisynaptic connection \\nSerial connection \\nSecond-order correlation \\nCommon input \\n.\\x7f (C IA) \\n: \\n% \\n\\x7f(AIC) \\nI% \\nI \\\\ \\n\\' \\\\\\x7f./\\x7f1 c) \\n:  \\nI \\n_/N. P2 (BIA) \\nFig. 2. Correlational effects of monosynaptic and disynaptic links between two neurons. \\nTop: monosynaptic excitatory link from A to B produces an increase in firing probability of B \\nafter A (left). As with all correlograms this is the time-inverted probability of increased firing \\nin A relative to B (right). Bottom: Two common disynaptic links between A and B are a \\nserial connection via C (left) and a common input from C. In both cases the effect of the \\ndisynaptic link is the convolution of the underlying monosynaptic links. \\n275 \\nThis relation means that the probability that a spike in cell A will \\nproduce a correlated spike in cell B would be the product of the two \\nprobabilities for the intervening monosynaptic connections. Given a typical \\nN of 01/EPSP, this would reduce the effectiveness of a given disynaptic \\np  \\nlinkage by two orders of magnitude relative to a monosynaptic connection. \\nHowever, the net strength of all the disynaptic linkages between two given \\ncells is proportional to the number of mediating interneurons {C}, since the \\neffects of parallel pathways add. Thus, the net potency of all the disynaptic \\nlinkages between two cells could approach that of a monosynaptic linkage if \\nthe number of mediating interneurons were sufficiently large. It should also \\nbe noted that some interneurons may fire more than once per E?S? and have \\na higher probability of being triggered to fire than motoneurons 11. \\nFor completeness, two other possible disynaptic links between A and B \\ninvolving a third cell C may be considered. One is a serial connection from B \\nto C to A, which is the reverse of the serial connection from A to B. This \\nwould produce a P2(B[A) with peak to the left of the origin. The fourth \\ncircuit involves convergent connections from both A and B to C; this is the \\nonly combination that would not produce any causal link between A and B. \\nThe effects of still higher-order polysynaptic linkages can be computed \\nsimilarly, by convolving the effects produced by the sequential connections. \\nFor example, trisynaptic linkages between four neurons are equivalent to \\ncombinations of disynaptic and monosynaptic connections. \\nThe cross-correlograms between two cells have a certain symmetry, \\ndepending on which is the reference cell. The cross-correlation histogram of \\ncell B referenced to A is identical to the time-inverted correlogram of A \\nreferenced to B. This is illustrated for the monosynaptic connection in Fig.2, \\ntop right, but is true for all correlograms. This symmetry represents the fact \\nthat the above-chance probability of B firing after A is the same as the \\nprobability of A firing before B: \\nP(BIA, t) = P(AIB,-t) \\n(5) \\nAs a consequence, polysynaptic correlational links can be computed as the \\nsame convolution integral (Eq. 4), independent of the direction of impulse \\npropagation. \\nPARALLEL PATHS AND FEEDBACK LOOPS \\nIn addition to the simple combinations of pair-wise connections \\nbetween neurons illustrated above, additional connections between the same \\ncells may form circuits with various kinds of loops. Recurrent connections \\ncan produce feedback loops, whose correlational effects are also calculated by \\nconvolving effects of the underlying synaptic links. Parallel feed-forward \\npaths can form multiple pathways between the same cells. These produce \\ncorrelational effects that are the sum of the effects of the individual \\nunderlying connections. \\nThe simplest feedback loop is formed by reciprocal connections \\nbetween a pair of cells. The effects of excitatory feedback can be computed by \\n276 \\nsuccessive convolutions of the underlying monosynaptic connections (Fig. 3 \\ntop). Note that such a positive feedback loop would be capable of sustaining \\nactivity only if the connections were sufficiently potent to ensure \\npostsynaptic firing. Since the probabilities of triggered firings at a single \\nsynapse are considerably less than one, reverberating activity can be \\nsustained only if the number of interacting cells is correspondingly increased. \\nThus, if the probability for a single link is on the order of .01, reverberating \\nactivity can be sustained if A and B are similarly interconnected with at least \\na hundred cells in parallel. \\nConnections between three neurons may produce various kinds of \\nloops. Feedforward parallel pathways are formed when cell A is \\nmonosynaptically connected to B and in addition has a serial disynaptic \\nconnection through C, as illustrated in Fig. 3 (bottom left); the correlational \\neffects of the two linkages from A to B would sum linearly, as shown for \\nexcitatory connections. Again, the effect of a larger set of cells {C} would be \\nadditive. Feedback loops could be formed with three cells by recurrent \\nconnections between any pair; the correlational consequences of the loop \\nagain are the convolution of the underlying links. Three cells can form \\nanother type loop if both A and B are monosynaptically connected, and \\nsimultaneously influenced by a common interneuron C (Fig. 3 bottom right). \\nIn this case the expected correlogram between A and B would be the sum of \\nthe individual components -- a common input peak around the origin plus a \\ndelayed peak produced by the serial connection. \\nFeedback loop \\n] .\\x7f1 (aim) P2(ata ) \\n\\'..,.i \"-.....\\' \\n, ?\\'., \\nI / \" .\" \\' \\nLi \"\\'\" \\nI \\nParallel feedforward path \\nP1 (BIA)+P2(BIA) \\nCommon input loop \\nI \\nP1 (BIA) +P2 (BIA) \\nFig. 3. Correlational effects of parallel connections between two neurons. Top: feedback \\nloop between two neurons A and B produces higher-order effects equivalent to convolution \\nof monosynaptic effects. Bottom: Loops formed by parallel feedforward paths (left) and by a \\ncommon input concurrent with a monosynaptic link (right) produce additive effects. \\n277 \\nCONCLUSIONS \\nThus, a simple computational algebra can be used to derive the \\ncorrelational effects of a given network structure. Effects of sequential \\nconnections can be computed by convolution and effects of parallel paths by \\nsummation. The inverse problem, of deducing the circuitry from the \\ncorrelational data is more difficult, since similar correlogram features may be \\nproduced by different circuits 9. \\nThe fact that monosynaptic links produce small correlational effects on \\nthe order of .01 represents a significant constraint in the mechanisms of \\ninformation processing in real neural nets. For example, secure propagation \\nof activity through serial polysynaptic linkages requires that the small \\nprobability of triggered firing via a given link is compensated by a \\nproportional increase in the number of parallel links. Thus, reliable serial \\nconduction would require hundreds of neurons at each level, with \\nappropriate divergent and convergent connections. It should also be noted \\nthat the effect of interneurons can be modulated by changing their activity. \\nThe intervening cells need to be active to mediate the correlational effects. As \\nindicated by eq. 1, the size of the correlogram peak is proportional to the \\nfiring rate (fo) of the postsynaptic cell. This allows dynamic modulation of \\npolysynaptic linkages. The greater the number of links, the more susceptible \\nthey are to modulation. \\nAcknowledgements: The author thanks Mr. Garrett Kenyon for stimulating \\ndiscussions and the cited colleagues for collaborative efforts. This work was \\nsupported in part by NIH grants NS 12542 and RR00166. \\nREFERENCES \\n1. Bishop, B., Reyes, A.D., and Fetz E.E., Soc. for Neurosci Abst. 11:157 (1985). \\n2. Cope, T.C., Fetz, E.E., and Matsumura, M., J. Physiol. 390:161-18 (1987). \\n3. Fetz, E.E. and Cheney, P.D., J. Neurophysiol. 44:751-772 (1980). \\n4. Fetz, E.E. and Gustafsson, B., J. Physiol. 341:387-410 (1983). \\n5. Gustafsson, B., and McCrea, D., J. Physiol. 347:431-451 (1984). \\n6. Kirkwood, P.A., J. Neurosci. Meth. 1:107-132 (1979). \\n7. Kirkwood, P.A., and Sears, T._ J. Physiol. 275:103-134 (1978). \\n8. Knox, C.K., Biophys. J. 14:567-582 (1974). \\n9. Moore, G.P., Segundo, J.P., Perkel, D.H. and Levitan, H., Biophys. !. 10:876- \\n900 (1970). \\n10. Reyes, A.D., Fetz E.E. and Schwindt, P.C., Soc. for Neurosci Abst. 13:157 \\n(1987). \\n11. Surmeier, D.J. and Weinberg, R.J., Brain Res. 331:180-184 (1985). \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVTEF1YEdszJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "872420cb-e9df-4681-969d-cb49d3dc5632"
      },
      "source": [
        "print(papers[0][:1000])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27O \n",
            "Correlational Strength and Computational Algebra \n",
            "of Synaptic Connections Between Neurons \n",
            "Eberhard E. Fetz \n",
            "Department of Physiology & Biophysics, \n",
            "University of Washington, Seattle, WA 98195 \n",
            "ABSTRACT \n",
            "Intracellular recordings in spinal cord motoneurons and cerebral \n",
            "cortex neurons have provided new evidence on the correlational strength of \n",
            "monosynaptic connections, and the relation between the shapes of \n",
            "postsynaptic potentials and the associated increased firing probability. In \n",
            "these cells, excitatory postsynaptic potentials (EPSPs) produce cross- \n",
            "correlogram peaks which resemble in large part the derivative of the EPSP. \n",
            "Additional synaptic noise broadens the peak, but the peak area -- i.e., the \n",
            "number of above-chance firings triggered per EPSP -- remains proportional to \n",
            "the EPSP amplitude. A typical EPSP of 100 gv triggers about .01 firings per \n",
            "EPSP. The consequences of these data for information processing by \n",
            "polysynaptic connections is discussed. The effects of sequ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjKbuIZYeutn",
        "colab_type": "text"
      },
      "source": [
        "**Basic Text Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcSxbeI1ed2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "017e057f-994d-4a6f-df2a-2defd2e55080"
      },
      "source": [
        "%%time\n",
        "import nltk\n",
        "import tqdm\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "\n",
        "def normalize_corpus(papers):\n",
        "    norm_papers = []\n",
        "    for paper in tqdm.tqdm(papers):\n",
        "        paper = paper.lower()\n",
        "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
        "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
        "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
        "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
        "        paper_tokens = list(filter(None, paper_tokens))\n",
        "        if paper_tokens:\n",
        "            norm_papers.append(paper_tokens)\n",
        "            \n",
        "    return norm_papers\n",
        "    \n",
        "norm_papers = normalize_corpus(papers)\n",
        "print(len(norm_papers))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1740/1740 [00:31<00:00, 55.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1740\n",
            "CPU times: user 31 s, sys: 400 ms, total: 31.4 s\n",
            "Wall time: 31.5 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F4UYb_efA2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ca5d6a99-7668-4f8f-f595-d54acaf11cac"
      },
      "source": [
        "print(norm_papers[0][:50])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['27o', 'correlational', 'strength', 'computational', 'algebra', 'synaptic', 'connection', 'neuron', 'eberhard', 'fetz', 'department', 'physiology', 'biophysics', 'university', 'washington', 'seattle', 'wa', 'abstract', 'intracellular', 'recording', 'spinal', 'cord', 'motoneuron', 'cerebral', 'cortex', 'neuron', 'provided', 'new', 'evidence', 'correlational', 'strength', 'monosynaptic', 'connection', 'relation', 'shape', 'postsynaptic', 'potential', 'associated', 'increased', 'firing', 'probability', 'cell', 'excitatory', 'postsynaptic', 'potential', 'epsps', 'produce', 'cross', 'correlogram', 'peak']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHdGIyv2f6Nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "306303a1-3c6b-4cfd-8b5b-0aa954ab2743"
      },
      "source": [
        "len(norm_papers),len(norm_papers[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1740, 1526)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbFnDmukk9S6",
        "colab_type": "text"
      },
      "source": [
        "**Build a Bi-gram Phrase Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Vrg9muk9uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "12debe12-8029-4d76-9747-63053854eb32"
      },
      "source": [
        "import gensim\n",
        "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter=b'_') # higher threshold fewer phrases.\n",
        "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
        "print(bigram_model[norm_papers[0]][:50])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['27o', 'correlational', 'strength', 'computational', 'algebra', 'synaptic', 'connection', 'neuron', 'eberhard', 'fetz', 'department', 'physiology', 'biophysics', 'university', 'washington', 'seattle', 'wa', 'abstract', 'intracellular_recording', 'spinal_cord', 'motoneuron', 'cerebral_cortex', 'neuron', 'provided', 'new', 'evidence', 'correlational', 'strength', 'monosynaptic', 'connection', 'relation', 'shape', 'postsynaptic_potential', 'associated', 'increased', 'firing', 'probability', 'cell', 'excitatory', 'postsynaptic_potential', 'epsps', 'produce', 'cross', 'correlogram', 'peak', 'resemble', 'large', 'part', 'derivative', 'epsp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSRFblBSgFQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFqZc4pHmBkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a942c2bb-e795-4a6c-a595-15a1dc1badcd"
      },
      "source": [
        "list(dictionary.items())[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '27o'),\n",
              " (1, 'abst'),\n",
              " (2, 'abstract'),\n",
              " (3, 'acknowledgement_author'),\n",
              " (4, 'action_potential'),\n",
              " (5, 'active'),\n",
              " (6, 'activity'),\n",
              " (7, 'add'),\n",
              " (8, 'addition'),\n",
              " (9, 'additional')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWywqY8amFQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f17aca01-224f-4d65-8b44-b213da139908"
      },
      "source": [
        "len(dictionary)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78892"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN9g-fPImY2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5daf0f3b-3c9c-44af-e9ef-7b25460ece2d"
      },
      "source": [
        "# Filter out words that occur less than 20 documents, or more than 60% of the documents.\n",
        "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
        "print('Total Vocabulary Size:', len(dictionary))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Vocabulary Size: 7756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjLJQoyImx6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6aa43250-4b15-436f-b476-1dc7d6a56fdd"
      },
      "source": [
        "# Transforming corpus into bag of words vectors\n",
        "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
        "print(bow_corpus[1][:50])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 2), (3, 2), (6, 5), (14, 6), (15, 1), (16, 1), (25, 2), (27, 2), (28, 2), (49, 2), (61, 1), (62, 5), (65, 1), (66, 1), (67, 3), (68, 2), (69, 1), (74, 3), (75, 4), (80, 1), (96, 1), (102, 1), (109, 1), (111, 2), (113, 1), (120, 4), (121, 37), (124, 1), (133, 1), (144, 1), (149, 27), (159, 1), (165, 4), (176, 3), (178, 2), (191, 2), (196, 1), (202, 1), (203, 3), (205, 2), (208, 14), (211, 1), (212, 2), (213, 9), (214, 1), (215, 3), (216, 1), (220, 1), (221, 1), (236, 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2N4QL75ncar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bc475d81-4e03-41f3-9394-6cd67279d5aa"
      },
      "source": [
        "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:]])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('abstract', 2), ('active', 2), ('addition', 5), ('allows', 6), ('although', 1), ('american_institute', 1), ('around', 2), ('arrow', 2), ('associated', 2), ('certain', 2), ('common', 1), ('comparison', 5), ('component', 1), ('computational', 1), ('computed', 3), ('computer', 2), ('conclusion', 1), ('connected', 3), ('connection', 4), ('considered', 1), ('cross', 1), ('decrease', 1), ('determined', 1), ('difference', 2), ('direct', 1), ('dynamic', 4), ('edge', 37), ('effort', 1), ('essentially', 1), ('feature', 1), ('fig', 27), ('four', 1), ('higher', 4), ('increase', 3), ('independent', 2), ('interconnected', 2), ('inverse', 1), ('largely', 1), ('larger', 3), ('le', 2), ('level', 14), ('linear', 1), ('linearly', 2), ('link', 9), ('long', 1), ('loop', 3), ('magnitude', 1), ('measured', 1), ('mechanism', 1), ('multiple', 2), ('order_magnitude', 9), ('pair', 1), ('parallel', 38), ('part', 1), ('per', 1), ('plotted', 2), ('plus', 2), ('produce', 2), ('product', 4), ('propagation', 1), ('provided', 3), ('provides', 1), ('range', 3), ('rate', 4), ('real', 1), ('reduce', 1), ('reduction', 3), ('relation', 2), ('relationship', 2), ('representing', 1), ('requires', 4), ('serial', 9), ('simulated', 4), ('simulation', 10), ('simultaneously', 1), ('size', 17), ('structure', 30), ('sum', 10), ('summation', 3), ('threshold', 1), ('top', 1), ('transform', 1), ('true', 1), ('type', 12), ('various', 2), ('2a', 1), ('2n', 6), ('2x', 3), ('ability', 1), ('acad', 1), ('across', 2), ('act', 17), ('acting', 1), ('activation', 49), ('adaptation', 3), ('added', 2), ('address', 11), ('affecting', 1), ('ai', 6), ('aj', 6), ('allow', 2), ('allowed', 1), ('allowing', 1), ('alternative', 1), ('amount', 1), ('applied', 1), ('applies', 1), ('apply', 2), ('applying', 1), ('april', 2), ('arbitrary', 1), ('architecture', 1), ('arithmetic', 1), ('array', 7), ('ascending', 2), ('assignment', 2), ('asynchronously', 1), ('attached', 4), ('average', 1), ('averaged', 1), ('back', 1), ('back_propagation', 4), ('backward', 6), ('basic', 2), ('becomes', 1), ('better', 1), ('black', 1), ('boolean', 2), ('brown', 1), ('cambridge_mass', 1), ('care', 1), ('category', 1), ('center', 1), ('change', 1), ('channel', 1), ('chosen', 2), ('ci', 1), ('circle', 1), ('clear', 1), ('cm', 45), ('code', 3), ('collective_computational', 1), ('collision', 1), ('column', 9), ('communication', 4), ('comparable', 1), ('compare', 2), ('compared', 1), ('complexity', 6), ('complicated', 1), ('composed', 3), ('composite', 24), ('computation', 11), ('compute', 3), ('computing', 1), ('configuration', 1), ('consideration', 1), ('consistent', 1), ('construct', 2), ('constructed', 1), ('construction', 1), ('content', 6), ('continue', 1), ('control', 10), ('conventional', 1), ('convergence', 2), ('copy', 7), ('corporation', 1), ('correspond', 1), ('cost', 1), ('cube', 8), ('current', 8), ('currently', 1), ('cycle', 3), ('def', 1), ('define', 2), ('defined', 6), ('defining', 1), ('degree', 1), ('deleted', 3), ('dependent', 3), ('descending', 2), ('desired', 2), ('determine', 1), ('differs', 1), ('digital', 1), ('dimensional', 2), ('distributed', 2), ('dominated', 1), ('dr', 1), ('drive', 1), ('efficient', 1), ('ei', 2), ('eight', 1), ('either', 1), ('element', 1), ('energy', 2), ('enhance', 1), ('enough', 1), ('equation', 3), ('etc', 1), ('every', 2), ('executed', 2), ('executes', 1), ('execution', 5), ('exemplar', 4), ('exist', 1), ('exp', 1), ('explicit', 1), ('exponential', 1), ('expressed', 1), ('fashion', 2), ('field', 1), ('five', 2), ('floating_point', 3), ('forcing', 1), ('forward', 6), ('forward_backward', 2), ('frequency', 1), ('functional', 1), ('fundamental', 1), ('gained', 1), ('generating', 1), ('geometry', 1), ('give', 1), ('global', 3), ('goal', 1), ('good', 1), ('graph', 3), ('grid', 4), ('growth', 1), ('hand', 1), ('handle', 2), ('hardware', 2), ('hebbian', 7), ('hebbian_learning', 2), ('hidden_unit', 1), ('hierarchical', 4), ('high', 1), ('high_speed', 1), ('hopfield', 9), ('host', 6), ('hypercube', 2), ('id', 15), ('identification', 2), ('ii_ii', 1), ('immediately', 1), ('implementation', 10), ('implemented', 4), ('implementing', 1), ('implied', 1), ('important', 1), ('include', 4), ('incoming', 4), ('indexing', 2), ('indirectly', 1), ('influence', 1), ('instruction', 3), ('insure', 2), ('integer', 3), ('interpretation', 1), ('interpreted', 2), ('involved', 2), ('issue', 1), ('iteration', 1), ('ix', 2), ('jr', 1), ('kernel', 11), ('laboratory', 1), ('last', 1), ('layer', 3), ('learn', 4), ('like', 2), ('limit', 4), ('line', 1), ('list', 26), ('location', 3), ('machine', 12), ('made', 1), ('maintain', 1), ('mal', 1), ('manipulated', 1), ('mapping', 6), ('matched', 1), ('matrix', 4), ('maximum', 1), ('meaning', 1), ('memory', 10), ('message', 4), ('metric', 1), ('minimize', 1), ('modest', 1), ('modification', 3), ('momentum', 2), ('movement', 2), ('moving', 1), ('multiplication', 6), ('must', 1), ('n2', 3), ('necessary', 1), ('nettalk', 1), ('neural', 1), ('never', 2), ('newly', 1), ('next_section', 2), ('ni', 1), ('nine', 1), ('non_zero', 2), ('nonlinear', 2), ('nonlinearity', 2), ('numerical', 1), ('obtained', 2), ('obvious', 1), ('oe', 1), ('offer', 1), ('old', 1), ('operation', 16), ('ordered', 1), ('others', 2), ('outgoing', 4), ('overhead', 3), ('overlap', 1), ('parallelism', 3), ('paris', 2), ('particular', 8), ('passive', 1), ('pattern', 8), ('per_second', 1), ('perform', 1), ('performed', 2), ('performing', 1), ('physic', 1), ('physical', 5), ('physically', 2), ('picked', 1), ('placed', 2), ('plot', 2), ('plotting', 1), ('pointer', 4), ('pp', 1), ('presented', 4), ('previous', 1), ('proc', 1), ('processed', 5), ('processor', 66), ('program', 2), ('programming', 2), ('proper', 1), ('provide', 4), ('providing', 1), ('put', 1), ('quite', 1), ('random', 1), ('rather', 1), ('realized', 1), ('receiver', 2), ('receiving', 1), ('reducing', 1), ('register', 1), ('remaining', 1), ('removed', 2), ('replaced', 1), ('represent', 4), ('representation', 7), ('represented', 3), ('require', 3), ('required', 9), ('requirement', 5), ('researcher', 1), ('reset', 3), ('resolution', 1), ('respectively', 2), ('retrieved', 1), ('rk', 1), ('roll', 1), ('roughly', 2), ('routine', 1), ('row_column', 2), ('run', 7), ('sample', 1), ('scale', 1), ('scan', 11), ('scanned', 1), ('scanning', 7), ('sec', 1), ('see_fig', 5), ('seg', 2), ('segment', 5), ('segmented', 9), ('selected', 6), ('selecting', 1), ('selection', 5), ('self', 4), ('sending', 1), ('sequentially', 2), ('setting', 1), ('sigma_pi', 1), ('simd', 1), ('simplicity', 1), ('simply', 1), ('simultaneous', 1), ('six', 6), ('solved', 1), ('spatially', 1), ('specified', 6), ('speed', 7), ('spiking', 1), ('spin_glass', 1), ('spread', 1), ('square', 1), ('sr', 1), ('st', 1), ('stable', 1), ('stack', 2), ('state', 1), ('step', 10), ('store', 11), ('stored', 6), ('stored_memory', 1), ('storing', 1), ('subset', 4), ('succession', 1), ('suggest', 2), ('suggests', 1), ('suite', 1), ('support', 1), ('supported', 1), ('symmetric', 2), ('synapsis', 1), ('synaptic_efficacy', 1), ('synchronously', 1), ('system_emergent', 1), ('table', 3), ('take', 1), ('talk', 1), ('technical_report', 2), ('temperature', 1), ('temporal', 2), ('test', 2), ('tested', 1), ('thinking', 2), ('total', 2), ('traffic', 1), ('transfer', 14), ('translated', 1), ('translation', 1), ('treatment', 4), ('tree', 3), ('triangle', 1), ('tum', 1), ('turn', 1), ('twelve', 1), ('uniform', 2), ('unique', 3), ('unit', 47), ('update', 30), ('updated', 7), ('updating', 2), ('us', 6), ('user', 1), ('usual', 1), ('utilization', 1), ('utilizing', 1), ('va', 1), ('variable', 1), ('variety', 1), ('versus', 1), ('viewed', 1), ('virtual', 12), ('vl', 1), ('vol', 1), ('weighted', 1), ('weighted_sum', 8), ('weighting', 1), ('well_known', 1), ('whereas', 1), ('white', 2), ('wide_range', 1), ('wii', 1), ('wij', 7), ('without', 1), ('wji', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txtLULUin6qp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecd4bf96-433c-4e73-d810-c7c629633cb0"
      },
      "source": [
        "print('Total number of papers:', len(bow_corpus))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of papers: 1740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pISvlxsj0Cg_",
        "colab_type": "text"
      },
      "source": [
        "**Topic Models with Latent Semantic Indexing (LSI)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2FB4Y-eoCa1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a79ca6ef-aeef-4786-b1f1-f69f9e711d5a"
      },
      "source": [
        "%%time\n",
        "\n",
        "TOTAL_TOPICS = 10\n",
        "lsi_bow = gensim.models.LsiModel(bow_corpus, id2word=dictionary, num_topics=TOTAL_TOPICS,\n",
        "                                 onepass=True, chunksize=1740, power_iters=1000)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6min 37s, sys: 1min 45s, total: 8min 23s\n",
            "Wall time: 5min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ism-yZ0Odp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "98a7a10f-2a7d-411a-dbf2-56f8c2ce909f"
      },
      "source": [
        "for topic_id, topic in lsi_bow.print_topics(num_topics=10, num_words=20):\n",
        "    print('Topic #'+str(topic_id+1)+':')\n",
        "    print(topic)\n",
        "    print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1:\n",
            "0.215*\"unit\" + 0.212*\"state\" + 0.187*\"training\" + 0.177*\"neuron\" + 0.162*\"pattern\" + 0.145*\"image\" + 0.140*\"vector\" + 0.125*\"feature\" + 0.122*\"cell\" + 0.110*\"layer\" + 0.101*\"task\" + 0.097*\"class\" + 0.091*\"probability\" + 0.089*\"signal\" + 0.087*\"step\" + 0.086*\"response\" + 0.085*\"representation\" + 0.083*\"noise\" + 0.082*\"rule\" + 0.081*\"distribution\"\n",
            "\n",
            "Topic #2:\n",
            "0.487*\"neuron\" + 0.396*\"cell\" + -0.257*\"state\" + 0.191*\"response\" + -0.187*\"training\" + 0.170*\"stimulus\" + 0.117*\"activity\" + -0.109*\"class\" + 0.099*\"spike\" + 0.097*\"pattern\" + 0.096*\"circuit\" + 0.096*\"synaptic\" + -0.095*\"vector\" + 0.090*\"signal\" + 0.090*\"firing\" + 0.088*\"visual\" + -0.084*\"classifier\" + -0.083*\"action\" + -0.078*\"word\" + 0.078*\"cortical\"\n",
            "\n",
            "Topic #3:\n",
            "-0.627*\"state\" + 0.395*\"image\" + -0.219*\"neuron\" + 0.209*\"feature\" + -0.188*\"action\" + 0.137*\"unit\" + 0.131*\"object\" + -0.130*\"control\" + 0.129*\"training\" + -0.109*\"policy\" + 0.103*\"classifier\" + 0.090*\"class\" + -0.081*\"step\" + -0.081*\"dynamic\" + 0.080*\"classification\" + 0.078*\"layer\" + 0.076*\"recognition\" + -0.074*\"reinforcement_learning\" + 0.069*\"representation\" + 0.068*\"pattern\"\n",
            "\n",
            "Topic #4:\n",
            "-0.686*\"unit\" + 0.433*\"image\" + -0.182*\"pattern\" + -0.131*\"layer\" + -0.123*\"hidden_unit\" + -0.121*\"net\" + -0.114*\"training\" + 0.112*\"feature\" + -0.109*\"activation\" + -0.107*\"rule\" + 0.097*\"neuron\" + -0.078*\"word\" + 0.070*\"pixel\" + -0.070*\"connection\" + 0.067*\"object\" + 0.065*\"state\" + 0.060*\"distribution\" + 0.059*\"face\" + -0.057*\"architecture\" + 0.055*\"estimate\"\n",
            "\n",
            "Topic #5:\n",
            "-0.428*\"image\" + -0.348*\"state\" + 0.266*\"neuron\" + -0.264*\"unit\" + 0.181*\"training\" + 0.174*\"class\" + -0.168*\"object\" + 0.167*\"classifier\" + -0.147*\"action\" + -0.122*\"visual\" + 0.117*\"vector\" + 0.115*\"node\" + 0.105*\"distribution\" + -0.103*\"motion\" + -0.099*\"feature\" + 0.097*\"classification\" + -0.097*\"control\" + -0.095*\"task\" + -0.087*\"cell\" + -0.083*\"representation\"\n",
            "\n",
            "Topic #6:\n",
            "0.660*\"cell\" + -0.508*\"neuron\" + -0.213*\"image\" + -0.103*\"chip\" + -0.097*\"unit\" + 0.093*\"response\" + -0.090*\"object\" + 0.083*\"rat\" + 0.076*\"distribution\" + -0.070*\"circuit\" + 0.069*\"probability\" + 0.064*\"stimulus\" + -0.061*\"memory\" + -0.058*\"analog\" + -0.058*\"activation\" + 0.055*\"class\" + -0.053*\"bit\" + -0.052*\"net\" + 0.051*\"cortical\" + 0.050*\"firing\"\n",
            "\n",
            "Topic #7:\n",
            "0.353*\"word\" + -0.281*\"unit\" + 0.272*\"training\" + 0.257*\"classifier\" + 0.177*\"recognition\" + -0.159*\"distribution\" + 0.152*\"feature\" + 0.144*\"state\" + 0.142*\"pattern\" + -0.141*\"vector\" + 0.128*\"cell\" + 0.128*\"task\" + -0.122*\"approximation\" + -0.121*\"variable\" + -0.110*\"equation\" + 0.107*\"classification\" + -0.106*\"noise\" + 0.103*\"class\" + -0.101*\"matrix\" + 0.098*\"neuron\"\n",
            "\n",
            "Topic #8:\n",
            "0.303*\"pattern\" + -0.243*\"signal\" + -0.236*\"control\" + -0.202*\"training\" + 0.181*\"rule\" + 0.178*\"state\" + -0.167*\"noise\" + 0.166*\"class\" + -0.162*\"word\" + 0.155*\"cell\" + 0.154*\"feature\" + -0.147*\"motion\" + -0.140*\"task\" + 0.127*\"node\" + 0.124*\"neuron\" + -0.116*\"target\" + -0.114*\"circuit\" + 0.114*\"probability\" + 0.110*\"classifier\" + 0.109*\"image\"\n",
            "\n",
            "Topic #9:\n",
            "0.472*\"node\" + 0.254*\"circuit\" + -0.214*\"word\" + 0.201*\"chip\" + -0.190*\"neuron\" + -0.172*\"stimulus\" + 0.160*\"classifier\" + 0.152*\"current\" + -0.147*\"feature\" + 0.146*\"voltage\" + -0.145*\"distribution\" + 0.141*\"control\" + 0.124*\"rule\" + 0.110*\"layer\" + 0.105*\"analog\" + 0.091*\"tree\" + -0.084*\"response\" + -0.080*\"state\" + -0.079*\"probability\" + -0.079*\"estimate\"\n",
            "\n",
            "Topic #10:\n",
            "-0.518*\"word\" + 0.254*\"training\" + -0.236*\"vector\" + 0.222*\"task\" + 0.194*\"pattern\" + 0.156*\"classifier\" + -0.149*\"node\" + -0.146*\"recognition\" + 0.139*\"control\" + -0.138*\"sequence\" + 0.126*\"rule\" + -0.125*\"circuit\" + -0.123*\"cell\" + 0.113*\"action\" + 0.105*\"neuron\" + -0.094*\"hmm\" + -0.093*\"character\" + -0.088*\"chip\" + -0.088*\"matrix\" + -0.085*\"structure\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7pjVABI1aHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acfca8d8-1a4c-4262-ec87-420c9c4695eb"
      },
      "source": [
        "for n in range(TOTAL_TOPICS):\n",
        "    print('Topic #'+str(n+1)+':')\n",
        "    print('='*50)\n",
        "    d1 = []\n",
        "    d2 = []\n",
        "    for term, wt in lsi_bow.show_topic(n, topn=20):\n",
        "        if wt >= 0:\n",
        "            d1.append((term, round(wt, 3)))\n",
        "        else:\n",
        "            d2.append((term, round(wt, 3)))\n",
        "\n",
        "    print('Direction 1:', d1)\n",
        "    print('-'*50)\n",
        "    print('Direction 2:', d2)\n",
        "    print('-'*50)\n",
        "    print()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1:\n",
            "==================================================\n",
            "Direction 1: [('unit', 0.215), ('state', 0.212), ('training', 0.187), ('neuron', 0.177), ('pattern', 0.162), ('image', 0.145), ('vector', 0.14), ('feature', 0.125), ('cell', 0.122), ('layer', 0.11), ('task', 0.101), ('class', 0.097), ('probability', 0.091), ('signal', 0.089), ('step', 0.087), ('response', 0.086), ('representation', 0.085), ('noise', 0.083), ('rule', 0.082), ('distribution', 0.081)]\n",
            "--------------------------------------------------\n",
            "Direction 2: []\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #2:\n",
            "==================================================\n",
            "Direction 1: [('neuron', 0.487), ('cell', 0.396), ('response', 0.191), ('stimulus', 0.17), ('activity', 0.117), ('spike', 0.099), ('pattern', 0.097), ('circuit', 0.096), ('synaptic', 0.096), ('signal', 0.09), ('firing', 0.09), ('visual', 0.088), ('cortical', 0.078)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('state', -0.257), ('training', -0.187), ('class', -0.109), ('vector', -0.095), ('classifier', -0.084), ('action', -0.083), ('word', -0.078)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #3:\n",
            "==================================================\n",
            "Direction 1: [('image', 0.395), ('feature', 0.209), ('unit', 0.137), ('object', 0.131), ('training', 0.129), ('classifier', 0.103), ('class', 0.09), ('classification', 0.08), ('layer', 0.078), ('recognition', 0.076), ('representation', 0.069), ('pattern', 0.068)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('state', -0.627), ('neuron', -0.219), ('action', -0.188), ('control', -0.13), ('policy', -0.109), ('step', -0.081), ('dynamic', -0.081), ('reinforcement_learning', -0.074)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #4:\n",
            "==================================================\n",
            "Direction 1: [('image', 0.433), ('feature', 0.112), ('neuron', 0.097), ('pixel', 0.07), ('object', 0.067), ('state', 0.065), ('distribution', 0.06), ('face', 0.059), ('estimate', 0.055)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('unit', -0.686), ('pattern', -0.182), ('layer', -0.131), ('hidden_unit', -0.123), ('net', -0.121), ('training', -0.114), ('activation', -0.109), ('rule', -0.107), ('word', -0.078), ('connection', -0.07), ('architecture', -0.057)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #5:\n",
            "==================================================\n",
            "Direction 1: [('neuron', 0.266), ('training', 0.181), ('class', 0.174), ('classifier', 0.167), ('vector', 0.117), ('node', 0.115), ('distribution', 0.105), ('classification', 0.097)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('image', -0.428), ('state', -0.348), ('unit', -0.264), ('object', -0.168), ('action', -0.147), ('visual', -0.122), ('motion', -0.103), ('feature', -0.099), ('control', -0.097), ('task', -0.095), ('cell', -0.087), ('representation', -0.083)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #6:\n",
            "==================================================\n",
            "Direction 1: [('cell', 0.66), ('response', 0.093), ('rat', 0.083), ('distribution', 0.076), ('probability', 0.069), ('stimulus', 0.064), ('class', 0.055), ('cortical', 0.051), ('firing', 0.05)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('neuron', -0.508), ('image', -0.213), ('chip', -0.103), ('unit', -0.097), ('object', -0.09), ('circuit', -0.07), ('memory', -0.061), ('analog', -0.058), ('activation', -0.058), ('bit', -0.053), ('net', -0.052)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #7:\n",
            "==================================================\n",
            "Direction 1: [('word', 0.353), ('training', 0.272), ('classifier', 0.257), ('recognition', 0.177), ('feature', 0.152), ('state', 0.144), ('pattern', 0.142), ('cell', 0.128), ('task', 0.128), ('classification', 0.107), ('class', 0.103), ('neuron', 0.098)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('unit', -0.281), ('distribution', -0.159), ('vector', -0.141), ('approximation', -0.122), ('variable', -0.121), ('equation', -0.11), ('noise', -0.106), ('matrix', -0.101)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #8:\n",
            "==================================================\n",
            "Direction 1: [('pattern', 0.303), ('rule', 0.181), ('state', 0.178), ('class', 0.166), ('cell', 0.155), ('feature', 0.154), ('node', 0.127), ('neuron', 0.124), ('probability', 0.114), ('classifier', 0.11), ('image', 0.109)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('signal', -0.243), ('control', -0.236), ('training', -0.202), ('noise', -0.167), ('word', -0.162), ('motion', -0.147), ('task', -0.14), ('target', -0.116), ('circuit', -0.114)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #9:\n",
            "==================================================\n",
            "Direction 1: [('node', 0.472), ('circuit', 0.254), ('chip', 0.201), ('classifier', 0.16), ('current', 0.152), ('voltage', 0.146), ('control', 0.141), ('rule', 0.124), ('layer', 0.11), ('analog', 0.105), ('tree', 0.091)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('word', -0.214), ('neuron', -0.19), ('stimulus', -0.172), ('feature', -0.147), ('distribution', -0.145), ('response', -0.084), ('state', -0.08), ('probability', -0.079), ('estimate', -0.079)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #10:\n",
            "==================================================\n",
            "Direction 1: [('training', 0.254), ('task', 0.222), ('pattern', 0.194), ('classifier', 0.156), ('control', 0.139), ('rule', 0.126), ('action', 0.113), ('neuron', 0.105)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('word', -0.518), ('vector', -0.236), ('node', -0.149), ('recognition', -0.146), ('sequence', -0.138), ('circuit', -0.125), ('cell', -0.123), ('hmm', -0.094), ('character', -0.093), ('chip', -0.088), ('matrix', -0.088), ('structure', -0.085)]\n",
            "--------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwJxUAf9NjHl",
        "colab_type": "text"
      },
      "source": [
        "**Getting U S AND VT Matrices**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E88tbpvE2ImM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e81fc313-198e-4e88-af8c-a6b77e1d4f1b"
      },
      "source": [
        "term_topic = lsi_bow.projection.u\n",
        "singular_values = lsi_bow.projection.s\n",
        "topic_document = (gensim.matutils.corpus2dense(lsi_bow[bow_corpus], len(singular_values)).T / singular_values).T\n",
        "term_topic.shape, singular_values.shape, topic_document.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:502: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  result = np.column_stack(sparse2full(doc, num_terms) for doc in corpus)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7756, 10), (10,), (10, 1740))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW8yUjjQNuPz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "30e7069a-65d9-4be4-e8f1-f2fd5905b00c"
      },
      "source": [
        "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
        "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
        "document_topics.head(15)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T1</th>\n",
              "      <th>T2</th>\n",
              "      <th>T3</th>\n",
              "      <th>T4</th>\n",
              "      <th>T5</th>\n",
              "      <th>T6</th>\n",
              "      <th>T7</th>\n",
              "      <th>T8</th>\n",
              "      <th>T9</th>\n",
              "      <th>T10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.022</td>\n",
              "      <td>0.049</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.001</td>\n",
              "      <td>-0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.038</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.009</td>\n",
              "      <td>-0.078</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>-0.031</td>\n",
              "      <td>-0.044</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.068</td>\n",
              "      <td>-0.037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.020</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>0.014</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.018</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.047</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>-0.014</td>\n",
              "      <td>-0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.022</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>-0.033</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.007</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.029</td>\n",
              "      <td>0.028</td>\n",
              "      <td>-0.010</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.031</td>\n",
              "      <td>-0.031</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>-0.035</td>\n",
              "      <td>0.007</td>\n",
              "      <td>-0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.027</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.017</td>\n",
              "      <td>-0.035</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.079</td>\n",
              "      <td>-0.075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.032</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>-0.014</td>\n",
              "      <td>0.035</td>\n",
              "      <td>-0.052</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.043</td>\n",
              "      <td>-0.010</td>\n",
              "      <td>0.029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.061</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.048</td>\n",
              "      <td>-0.127</td>\n",
              "      <td>-0.050</td>\n",
              "      <td>-0.027</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>0.116</td>\n",
              "      <td>-0.026</td>\n",
              "      <td>-0.061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.023</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.031</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>-0.021</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.012</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.007</td>\n",
              "      <td>-0.018</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.004</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.054</td>\n",
              "      <td>0.102</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.067</td>\n",
              "      <td>0.044</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>0.056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.015</td>\n",
              "      <td>0.023</td>\n",
              "      <td>-0.010</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>0.010</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.004</td>\n",
              "      <td>-0.004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.024</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.044</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.027</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.041</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>-0.036</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.010</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.010</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.011</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
              "0   0.022  0.049 -0.011  0.004  0.013  0.031  0.011  0.013  0.001 -0.013\n",
              "1   0.038  0.003  0.009 -0.078 -0.023 -0.031 -0.044  0.015  0.068 -0.037\n",
              "2   0.020 -0.005  0.014 -0.008  0.018 -0.008  0.047 -0.011 -0.014 -0.017\n",
              "3   0.022 -0.004 -0.033  0.008 -0.029  0.008  0.009  0.007 -0.016 -0.003\n",
              "4   0.029  0.028 -0.010  0.016  0.031 -0.031 -0.005 -0.035  0.007 -0.000\n",
              "5   0.027  0.007  0.006  0.017  0.017 -0.035  0.008  0.001  0.079 -0.075\n",
              "6   0.032  0.036 -0.011 -0.014  0.035 -0.052  0.016  0.043 -0.010  0.029\n",
              "7   0.061  0.004  0.048 -0.127 -0.050 -0.027 -0.063  0.116 -0.026 -0.061\n",
              "8   0.023  0.003  0.006  0.031 -0.016 -0.004 -0.028 -0.021  0.046 -0.021\n",
              "9   0.012 -0.006  0.007 -0.018  0.008 -0.001  0.004 -0.005  0.003  0.013\n",
              "10  0.054  0.102 -0.009 -0.019 -0.006  0.067  0.044 -0.004 -0.082  0.056\n",
              "11  0.015  0.023 -0.010 -0.005  0.010 -0.013 -0.001  0.005  0.004 -0.004\n",
              "12  0.024  0.048  0.011  0.003 -0.023  0.044  0.002  0.011  0.003 -0.016\n",
              "13  0.027 -0.007  0.027  0.041 -0.016 -0.008 -0.036 -0.006  0.005 -0.006\n",
              "14  0.010  0.005 -0.010  0.009  0.011 -0.017 -0.013  0.003  0.005 -0.010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBiNbd8LNyMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "199f8f5c-755e-4ba2-958e-94923f7f4aeb"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "for document_number in range(200,205):\n",
        "    top_topics = list(document_topics.columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
        "    print('Document #'+str(document_number)+':')\n",
        "    print('Dominant Topics (top 3):', top_topics)\n",
        "    print('Paper Summary:')\n",
        "    print(papers[document_number][:500])\n",
        "    print()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document #200:\n",
            "Dominant Topics (top 3): ['T7', 'T5', 'T1']\n",
            "Paper Summary:\n",
            "622 Atlas, Cole, Connor, EI-Sharkawi, Marks, Muthusamy and Barnard \n",
            "Performance Comparisons Between \n",
            "Backpropagation Networks and Classification \n",
            "on Three Real-World Applications \n",
            "Trees \n",
            "Les Atlas \n",
            "Dept. of EE, FT-10 \n",
            "University of Washington \n",
            "Seattle, Washington 98195 \n",
            "Ronald Cole \n",
            "Dept. of CS&E \n",
            "Oregon Graduate Institute \n",
            "Beaverton, Oregon 97006 \n",
            "Jerome Connor, Mohamed EI-Sharkawi, and Robert J. Marks II \n",
            "University of Washington \n",
            "Yeshwant Muthusamy \n",
            "Oregon Graduate Institute \n",
            "Etienne Barnard \n",
            "\n",
            "Document #201:\n",
            "Dominant Topics (top 3): ['T8', 'T1', 'T7']\n",
            "Paper Summary:\n",
            "240 Lee \n",
            "Using A Translation-lnvariant Neural Network \n",
            "To Diagnose Heart Arrhythmia \n",
            "Susan Ciarrocca Lee \n",
            "The Johns Hopkins University \n",
            "Applied Physics Laboratory \n",
            "Laurel, Maryland 20707 \n",
            "ABSTRACT \n",
            "Distinctive electrocardiogram (ECG) patterns are created when the heart \n",
            "is beating normally and when a d_angerous arrhythmia is present. Some \n",
            "devices which monitor the ECG and react to arrhythmias parameterize \n",
            "the ECG signal and make a diagnosis based on the parameters. The \n",
            "author discusses the us\n",
            "\n",
            "Document #202:\n",
            "Dominant Topics (top 3): ['T4', 'T8', 'T7']\n",
            "Paper Summary:\n",
            "100 Servan-Schreiber, Printz and Cohen \n",
            "The Effect of Catecholamines on Performance: \n",
            "From Unit to System Behavior \n",
            "David Servan-Schreiber, Harry Printz and Jonathan D. Cohen \n",
            "School of Computer Science and Department of Psychology \n",
            "Carnegie Mellon University \n",
            "Pittsburgh, PA 15213 \n",
            "ABSTRACT \n",
            "At the level of individual neurons, catecholamine release increases the \n",
            "responsivity of cells to excitatory and inhibitory inputs. We present a \n",
            "model of catecholamine effects in a network of neural-like el\n",
            "\n",
            "Document #203:\n",
            "Dominant Topics (top 3): ['T9', 'T1', 'T10']\n",
            "Paper Summary:\n",
            "650 Lincoln and Skrzypek \n",
            "Synergy Of Clustering Multiple Back Propagation Networks \n",
            "William P. Lincoln* and Josef SkrzypekP \n",
            "UCLA Machine Perception Laboratory \n",
            "Computer Science Department \n",
            "Los Angeles, CA 90024 \n",
            "ABSTRACT \n",
            "The properties of a cluster of multiple back-propagation (BP) networks \n",
            "are examined and compared to the performance of a single BP net- \n",
            "work. The underlying idea is that a synergistic effect within the cluster \n",
            "improves the performance and fault tolerance. Five networks were\n",
            "\n",
            "Document #204:\n",
            "Dominant Topics (top 3): ['T3', 'T6', 'T9']\n",
            "Paper Summary:\n",
            "Non-Boltzmann Dynamics in Networks of Spiking Neurons 109 \n",
            "Non-Boltzmann Dynamics in \n",
            "Spiking Neurons \n",
            "Networks of \n",
            "Michael C. Crair and William Bialek \n",
            "Department of Physics, and \n",
            "Department of Molecular and Cell Biology \n",
            "University of California at Berkeley \n",
            "Berkeley, CA 94720 \n",
            "ABSTRACT \n",
            "We study networks of spiking neurons in which spikes are fired as \n",
            "a Poisson process. The state of a cell is determined by the instan- \n",
            "taneous firing rate, and in the limit of high firing rates our model \n",
            "red\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FthvtAGxO9gQ",
        "colab_type": "text"
      },
      "source": [
        "**Implementing LSI Models from Scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR7lKrObPlEj",
        "colab_type": "text"
      },
      "source": [
        "**Creating Term-Document Matrix**\n",
        "\n",
        "1.   **The first step in SVD is to get the source matrix, which is typically a term-document matrix. We can obtain it from Gensim by converting the sparse Bag of Words representation into a dense matrix.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2oIQSEFOS7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ad872218-6bf0-4cb2-b0a5-102923ef5695"
      },
      "source": [
        "td_matrix = gensim.matutils.corpus2dense(corpus=bow_corpus, num_terms=len(dictionary))\n",
        "print(td_matrix.shape)\n",
        "td_matrix"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:502: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  result = np.column_stack(sparse2full(doc, num_terms) for doc in corpus)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7756, 1740)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2., 0., ..., 1., 1., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [2., 0., 0., ..., 2., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1cNJAPNP9Du",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2d057b10-4a7f-47cc-ac72-75a02ebcd0df"
      },
      "source": [
        "vocabulary = np.array(list(dictionary.values()))\n",
        "print('Total vocabulary size:', len(vocabulary))\n",
        "vocabulary"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total vocabulary size: 7756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['abstract', 'acknowledgement_author', 'action_potential', ...,\n",
              "       'smola', 'mozer_jordan', 'kearns_solla'], dtype='<U28')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mDgW0byQMjl",
        "colab_type": "text"
      },
      "source": [
        "**Performing SVD Matrix on Term-Document Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-ClPWM9QCHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45f3e0d4-1bf8-4e31-83ca-b96ce3e2eff9"
      },
      "source": [
        "\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "u, s, vt = svds(td_matrix, k=TOTAL_TOPICS, maxiter=10000)\n",
        "term_topic = u\n",
        "singular_values = s\n",
        "topic_document = vt\n",
        "term_topic.shape, singular_values.shape, topic_document.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7756, 10), (10,), (10, 1740))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "briQQuZLQ4ms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f80e33e-ee0c-45e3-fbb5-e63528117452"
      },
      "source": [
        "tt_weights = term_topic.transpose() * singular_values[:, None]\n",
        "tt_weights.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 7756)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PJOGcw-QbRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7650e94a-6aea-4ae0-91c7-54fc73bc6c72"
      },
      "source": [
        "top_terms = 20\n",
        "topic_key_term_idxs = np.argsort(-np.absolute(tt_weights), axis=1)[:, :top_terms]\n",
        "topic_keyterm_weights = np.array([tt_weights[row, columns] \n",
        "                             for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
        "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
        "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
        "for n in range(TOTAL_TOPICS):\n",
        "    print('Topic #'+str(n+1)+':')\n",
        "    print('='*50)\n",
        "    d1 = []\n",
        "    d2 = []\n",
        "    terms, weights = topic_keyterms_weights[n]\n",
        "    term_weights = sorted([(t, w) for t, w in zip(terms, weights)], \n",
        "                          key=lambda row: -abs(row[1]))\n",
        "    for term, wt in term_weights:\n",
        "        if wt >= 0:\n",
        "            d1.append((term, round(wt, 3)))\n",
        "        else:\n",
        "            d2.append((term, round(wt, 3)))\n",
        "\n",
        "    print('Direction 1:', d1)\n",
        "    print('-'*50)\n",
        "    print('Direction 2:', d2)\n",
        "    print('-'*50)\n",
        "    print()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1:\n",
            "==================================================\n",
            "Direction 1: [('word', 188.486), ('vector', 85.972), ('node', 54.38), ('recognition', 53.231), ('sequence', 50.35), ('circuit', 45.396), ('cell', 44.811), ('hmm', 34.085), ('character', 34.022), ('chip', 32.162), ('matrix', 32.092), ('structure', 30.993)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('training', -92.618), ('task', -80.732), ('pattern', -70.619), ('classifier', -56.987), ('control', -50.676), ('rule', -45.925), ('action', -41.201), ('neuron', -38.195)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #2:\n",
            "==================================================\n",
            "Direction 1: [('word', 78.351), ('neuron', 69.792), ('stimulus', 63.233), ('feature', 53.819), ('distribution', 53.119), ('response', 30.954), ('state', 29.343), ('probability', 29.1), ('estimate', 28.908)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('node', -173.276), ('circuit', -92.999), ('chip', -73.593), ('classifier', -58.718), ('current', -55.844), ('voltage', -53.489), ('control', -51.709), ('rule', -45.295), ('layer', -40.265), ('analog', -38.343), ('tree', -33.483)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #3:\n",
            "==================================================\n",
            "Direction 1: [('signal', 93.805), ('control', 91.041), ('training', 77.88), ('noise', 64.397), ('word', 62.391), ('motion', 56.699), ('task', 53.883), ('target', 44.765), ('circuit', 44.129)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('pattern', -116.971), ('rule', -69.783), ('state', -68.605), ('class', -64.259), ('cell', -59.979), ('feature', -59.606), ('node', -49.175), ('neuron', -47.998), ('probability', -43.813), ('classifier', -42.612), ('image', -42.061)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #4:\n",
            "==================================================\n",
            "Direction 1: [('word', 147.792), ('training', 113.693), ('classifier', 107.386), ('recognition', 73.948), ('feature', 63.454), ('state', 60.126), ('pattern', 59.561), ('cell', 53.769), ('task', 53.693), ('classification', 44.936), ('class', 43.161), ('neuron', 41.092)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('unit', -117.727), ('distribution', -66.719), ('vector', -58.881), ('approximation', -50.931), ('variable', -50.83), ('equation', -46.229), ('noise', -44.247), ('matrix', -42.214)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #5:\n",
            "==================================================\n",
            "Direction 1: [('neuron', 220.116), ('image', 92.39), ('chip', 44.422), ('unit', 41.922), ('object', 39.001), ('circuit', 30.444), ('memory', 26.475), ('analog', 25.207), ('activation', 24.953), ('bit', 22.997), ('net', 22.699)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('cell', -285.803), ('response', -40.216), ('rat', -35.975), ('distribution', -33.085), ('probability', -29.79), ('stimulus', -27.789), ('class', -24.02), ('cortical', -22.185), ('firing', -21.66)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #6:\n",
            "==================================================\n",
            "Direction 1: [('neuron', 130.053), ('training', 88.668), ('class', 85.213), ('classifier', 81.92), ('vector', 57.531), ('node', 56.341), ('distribution', 51.622), ('classification', 47.645)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('image', -209.795), ('state', -170.207), ('unit', -129.105), ('object', -82.185), ('action', -72.136), ('visual', -59.503), ('motion', -50.605), ('feature', -48.665), ('control', -47.427), ('task', -46.496), ('cell', -42.366), ('representation', -40.564)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #7:\n",
            "==================================================\n",
            "Direction 1: [('unit', 341.83), ('pattern', 90.771), ('layer', 65.337), ('hidden_unit', 61.12), ('net', 60.035), ('training', 56.741), ('activation', 54.268), ('rule', 53.377), ('word', 38.903), ('connection', 34.618), ('architecture', 28.439)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('image', -215.856), ('feature', -55.647), ('neuron', -48.496), ('pixel', -35.095), ('object', -33.584), ('state', -32.542), ('distribution', -29.977), ('face', -29.256), ('estimate', -27.556)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #8:\n",
            "==================================================\n",
            "Direction 1: [('state', 364.388), ('neuron', 127.022), ('action', 109.245), ('control', 75.369), ('policy', 63.103), ('step', 47.226), ('dynamic', 46.907), ('reinforcement_learning', 42.747)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('image', -229.287), ('feature', -121.397), ('unit', -79.44), ('object', -76.204), ('training', -75.153), ('classifier', -59.872), ('class', -52.527), ('classification', -46.696), ('layer', -45.149), ('recognition', -44.192), ('representation', -40.179), ('pattern', -39.252)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #9:\n",
            "==================================================\n",
            "Direction 1: [('neuron', 306.151), ('cell', 249.243), ('response', 119.758), ('stimulus', 106.762), ('activity', 73.499), ('spike', 62.039), ('pattern', 60.957), ('circuit', 60.602), ('synaptic', 60.282), ('signal', 56.665), ('firing', 56.597), ('visual', 55.571), ('cortical', 48.867)]\n",
            "--------------------------------------------------\n",
            "Direction 2: [('state', -161.466), ('training', -117.319), ('class', -68.732), ('vector', -59.558), ('classifier', -52.589), ('action', -52.113), ('word', -49.239)]\n",
            "--------------------------------------------------\n",
            "\n",
            "Topic #10:\n",
            "==================================================\n",
            "Direction 1: [('unit', 260.793), ('state', 258.146), ('training', 227.312), ('neuron', 215.681), ('pattern', 197.232), ('image', 175.735), ('vector', 170.154), ('feature', 151.547), ('cell', 148.138), ('layer', 133.593), ('task', 122.389), ('class', 117.849), ('probability', 110.526), ('signal', 108.232), ('step', 105.202), ('response', 104.465), ('representation', 103.255), ('noise', 100.573), ('rule', 99.611), ('distribution', 98.973)]\n",
            "--------------------------------------------------\n",
            "Direction 2: []\n",
            "--------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d-ME16mQzi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "96dbd2e5-7df6-4372-9b4c-64f1e514afef"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
        "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
        "document_topics.head(15)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T1</th>\n",
              "      <th>T2</th>\n",
              "      <th>T3</th>\n",
              "      <th>T4</th>\n",
              "      <th>T5</th>\n",
              "      <th>T6</th>\n",
              "      <th>T7</th>\n",
              "      <th>T8</th>\n",
              "      <th>T9</th>\n",
              "      <th>T10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>0.011</td>\n",
              "      <td>-0.031</td>\n",
              "      <td>0.013</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.037</td>\n",
              "      <td>-0.068</td>\n",
              "      <td>-0.015</td>\n",
              "      <td>-0.044</td>\n",
              "      <td>0.031</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.078</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.017</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.047</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.014</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003</td>\n",
              "      <td>0.016</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>0.009</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.033</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>0.022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>0.035</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.031</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.028</td>\n",
              "      <td>0.029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.075</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.035</td>\n",
              "      <td>0.017</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.029</td>\n",
              "      <td>0.010</td>\n",
              "      <td>-0.043</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.052</td>\n",
              "      <td>0.035</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.061</td>\n",
              "      <td>0.026</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>0.027</td>\n",
              "      <td>-0.050</td>\n",
              "      <td>0.127</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.021</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>0.021</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>0.004</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.031</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.013</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.018</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.056</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.044</td>\n",
              "      <td>-0.067</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.004</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.016</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>0.002</td>\n",
              "      <td>-0.044</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.006</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>0.006</td>\n",
              "      <td>-0.036</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.041</td>\n",
              "      <td>-0.027</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>0.027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.010</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.011</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
              "0   0.013 -0.001 -0.013  0.011 -0.031  0.013 -0.004  0.011  0.049  0.022\n",
              "1   0.037 -0.068 -0.015 -0.044  0.031 -0.023  0.078 -0.009  0.003  0.038\n",
              "2   0.017  0.014  0.011  0.047  0.008  0.018  0.008 -0.014 -0.005  0.020\n",
              "3   0.003  0.016 -0.007  0.009 -0.008 -0.029 -0.008  0.033 -0.004  0.022\n",
              "4   0.000 -0.007  0.035 -0.005  0.031  0.031 -0.016  0.010  0.028  0.029\n",
              "5   0.075 -0.079 -0.001  0.008  0.035  0.017 -0.017 -0.006  0.007  0.027\n",
              "6  -0.029  0.010 -0.043  0.016  0.052  0.035  0.014  0.011  0.036  0.032\n",
              "7   0.061  0.026 -0.116 -0.063  0.027 -0.050  0.127 -0.048  0.004  0.061\n",
              "8   0.021 -0.046  0.021 -0.028  0.004 -0.016 -0.031 -0.006  0.003  0.023\n",
              "9  -0.013 -0.003  0.005  0.004  0.001  0.008  0.018 -0.007 -0.006  0.012\n",
              "10 -0.056  0.082  0.004  0.044 -0.067 -0.006  0.019  0.009  0.102  0.054\n",
              "11  0.004 -0.004 -0.005 -0.001  0.013  0.010  0.005  0.010  0.023  0.015\n",
              "12  0.016 -0.003 -0.011  0.002 -0.044 -0.023 -0.003 -0.011  0.048  0.024\n",
              "13  0.006 -0.005  0.006 -0.036  0.008 -0.016 -0.041 -0.027 -0.007  0.027\n",
              "14  0.010 -0.005 -0.003 -0.013  0.017  0.011 -0.009  0.010  0.005  0.010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3ZbbfhCQ-1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b64948c-b140-44b2-e830-b2760f8180e2"
      },
      "source": [
        "\n",
        "\n",
        "for document_number in range(200,204):\n",
        "    top_topics = list(document_topics.columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
        "    print('Document #'+str(document_number)+':')\n",
        "    print('Dominant Topics (top 3):', top_topics)\n",
        "    print('Paper Summary:')\n",
        "    print(papers[document_number][:500])\n",
        "    print()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document #200:\n",
            "Dominant Topics (top 3): ['T4', 'T6', 'T10']\n",
            "Paper Summary:\n",
            "622 Atlas, Cole, Connor, EI-Sharkawi, Marks, Muthusamy and Barnard \n",
            "Performance Comparisons Between \n",
            "Backpropagation Networks and Classification \n",
            "on Three Real-World Applications \n",
            "Trees \n",
            "Les Atlas \n",
            "Dept. of EE, FT-10 \n",
            "University of Washington \n",
            "Seattle, Washington 98195 \n",
            "Ronald Cole \n",
            "Dept. of CS&E \n",
            "Oregon Graduate Institute \n",
            "Beaverton, Oregon 97006 \n",
            "Jerome Connor, Mohamed EI-Sharkawi, and Robert J. Marks II \n",
            "University of Washington \n",
            "Yeshwant Muthusamy \n",
            "Oregon Graduate Institute \n",
            "Etienne Barnard \n",
            "\n",
            "Document #201:\n",
            "Dominant Topics (top 3): ['T3', 'T10', 'T4']\n",
            "Paper Summary:\n",
            "240 Lee \n",
            "Using A Translation-lnvariant Neural Network \n",
            "To Diagnose Heart Arrhythmia \n",
            "Susan Ciarrocca Lee \n",
            "The Johns Hopkins University \n",
            "Applied Physics Laboratory \n",
            "Laurel, Maryland 20707 \n",
            "ABSTRACT \n",
            "Distinctive electrocardiogram (ECG) patterns are created when the heart \n",
            "is beating normally and when a d_angerous arrhythmia is present. Some \n",
            "devices which monitor the ECG and react to arrhythmias parameterize \n",
            "the ECG signal and make a diagnosis based on the parameters. The \n",
            "author discusses the us\n",
            "\n",
            "Document #202:\n",
            "Dominant Topics (top 3): ['T7', 'T3', 'T4']\n",
            "Paper Summary:\n",
            "100 Servan-Schreiber, Printz and Cohen \n",
            "The Effect of Catecholamines on Performance: \n",
            "From Unit to System Behavior \n",
            "David Servan-Schreiber, Harry Printz and Jonathan D. Cohen \n",
            "School of Computer Science and Department of Psychology \n",
            "Carnegie Mellon University \n",
            "Pittsburgh, PA 15213 \n",
            "ABSTRACT \n",
            "At the level of individual neurons, catecholamine release increases the \n",
            "responsivity of cells to excitatory and inhibitory inputs. We present a \n",
            "model of catecholamine effects in a network of neural-like el\n",
            "\n",
            "Document #203:\n",
            "Dominant Topics (top 3): ['T2', 'T10', 'T1']\n",
            "Paper Summary:\n",
            "650 Lincoln and Skrzypek \n",
            "Synergy Of Clustering Multiple Back Propagation Networks \n",
            "William P. Lincoln* and Josef SkrzypekP \n",
            "UCLA Machine Perception Laboratory \n",
            "Computer Science Department \n",
            "Los Angeles, CA 90024 \n",
            "ABSTRACT \n",
            "The properties of a cluster of multiple back-propagation (BP) networks \n",
            "are examined and compared to the performance of a single BP net- \n",
            "work. The underlying idea is that a synergistic effect within the cluster \n",
            "improves the performance and fault tolerance. Five networks were\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhRP0HsbTsB3",
        "colab_type": "text"
      },
      "source": [
        "**Topic Models with Latent Dirichlet Allocation (LDA)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuuV0-DrRBY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "effe9ae1-83a9-4320-b1d2-55cdd2c0f648"
      },
      "source": [
        "%%time\n",
        "\n",
        "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740, \n",
        "                                   alpha='auto', eta='auto', random_state=42,\n",
        "                                   iterations=500, num_topics=TOTAL_TOPICS, \n",
        "                                   passes=20, eval_every=None)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 16s, sys: 2.1 s, total: 2min 18s\n",
            "Wall time: 2min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayE23YeETy80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "1c97f970-106d-45f6-cc2b-d1a9540b793d"
      },
      "source": [
        "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
        "    print('Topic #'+str(topic_id+1)+':')\n",
        "    print(topic)\n",
        "    print()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1:\n",
            "0.021*\"cell\" + 0.011*\"stimulus\" + 0.010*\"response\" + 0.009*\"neuron\" + 0.007*\"unit\" + 0.007*\"activity\" + 0.006*\"pattern\" + 0.006*\"visual\" + 0.005*\"map\" + 0.005*\"cortical\" + 0.005*\"receptive_field\" + 0.005*\"spike\" + 0.005*\"layer\" + 0.004*\"orientation\" + 0.004*\"spatial\" + 0.004*\"cortex\" + 0.004*\"correlation\" + 0.003*\"effect\" + 0.003*\"neural\" + 0.003*\"contrast\"\n",
            "\n",
            "Topic #2:\n",
            "0.007*\"distribution\" + 0.006*\"gaussian\" + 0.005*\"variable\" + 0.005*\"vector\" + 0.005*\"estimate\" + 0.005*\"prior\" + 0.005*\"approximation\" + 0.004*\"mixture\" + 0.004*\"probability\" + 0.004*\"density\" + 0.004*\"sample\" + 0.004*\"matrix\" + 0.004*\"bayesian\" + 0.004*\"structure\" + 0.003*\"variance\" + 0.003*\"training\" + 0.003*\"linear\" + 0.003*\"unit\" + 0.003*\"equation\" + 0.003*\"step\"\n",
            "\n",
            "Topic #3:\n",
            "0.010*\"motion\" + 0.010*\"signal\" + 0.010*\"control\" + 0.007*\"target\" + 0.006*\"visual\" + 0.005*\"movement\" + 0.005*\"velocity\" + 0.005*\"position\" + 0.005*\"response\" + 0.005*\"motor\" + 0.005*\"filter\" + 0.004*\"frequency\" + 0.004*\"trajectory\" + 0.004*\"sound\" + 0.004*\"subject\" + 0.004*\"direction\" + 0.004*\"unit\" + 0.004*\"auditory\" + 0.003*\"task\" + 0.003*\"field\"\n",
            "\n",
            "Topic #4:\n",
            "0.029*\"neuron\" + 0.009*\"circuit\" + 0.008*\"pattern\" + 0.007*\"current\" + 0.007*\"synaptic\" + 0.006*\"voltage\" + 0.005*\"cell\" + 0.005*\"connection\" + 0.005*\"memory\" + 0.005*\"neural\" + 0.005*\"state\" + 0.005*\"activity\" + 0.005*\"dynamic\" + 0.004*\"synapsis\" + 0.004*\"signal\" + 0.004*\"synapse\" + 0.004*\"response\" + 0.004*\"threshold\" + 0.003*\"analog\" + 0.003*\"firing\"\n",
            "\n",
            "Topic #5:\n",
            "0.023*\"state\" + 0.012*\"unit\" + 0.007*\"action\" + 0.007*\"task\" + 0.006*\"step\" + 0.006*\"control\" + 0.005*\"training\" + 0.004*\"policy\" + 0.004*\"sequence\" + 0.004*\"hidden_unit\" + 0.004*\"recurrent\" + 0.004*\"reinforcement_learning\" + 0.004*\"rule\" + 0.003*\"net\" + 0.003*\"architecture\" + 0.003*\"memory\" + 0.003*\"environment\" + 0.003*\"learn\" + 0.003*\"optimal\" + 0.003*\"dynamic\"\n",
            "\n",
            "Topic #6:\n",
            "0.007*\"vector\" + 0.006*\"let\" + 0.005*\"equation\" + 0.005*\"bound\" + 0.004*\"linear\" + 0.004*\"theorem\" + 0.004*\"training\" + 0.004*\"probability\" + 0.004*\"optimal\" + 0.004*\"distribution\" + 0.004*\"solution\" + 0.004*\"class\" + 0.004*\"theory\" + 0.004*\"convergence\" + 0.004*\"size\" + 0.004*\"matrix\" + 0.004*\"approximation\" + 0.004*\"consider\" + 0.004*\"rate\" + 0.003*\"defined\"\n",
            "\n",
            "Topic #7:\n",
            "0.041*\"image\" + 0.016*\"feature\" + 0.016*\"object\" + 0.009*\"pixel\" + 0.007*\"layer\" + 0.006*\"view\" + 0.005*\"face\" + 0.005*\"recognition\" + 0.005*\"unit\" + 0.005*\"representation\" + 0.004*\"region\" + 0.004*\"pattern\" + 0.004*\"training\" + 0.004*\"task\" + 0.004*\"location\" + 0.004*\"edge\" + 0.004*\"position\" + 0.004*\"visual\" + 0.003*\"level\" + 0.003*\"scene\"\n",
            "\n",
            "Topic #8:\n",
            "0.011*\"signal\" + 0.009*\"source\" + 0.007*\"cluster\" + 0.007*\"component\" + 0.006*\"code\" + 0.006*\"channel\" + 0.005*\"ica\" + 0.005*\"vector\" + 0.005*\"clustering\" + 0.005*\"noise\" + 0.005*\"representation\" + 0.004*\"linear\" + 0.004*\"matrix\" + 0.004*\"pca\" + 0.004*\"variable\" + 0.003*\"eeg\" + 0.003*\"correlation\" + 0.003*\"independent_component\" + 0.003*\"image\" + 0.003*\"coding\"\n",
            "\n",
            "Topic #9:\n",
            "0.015*\"training\" + 0.012*\"classifier\" + 0.010*\"class\" + 0.010*\"classification\" + 0.008*\"pattern\" + 0.006*\"node\" + 0.006*\"test\" + 0.006*\"vector\" + 0.005*\"training_set\" + 0.005*\"feature\" + 0.004*\"chip\" + 0.004*\"bit\" + 0.004*\"application\" + 0.004*\"size\" + 0.004*\"trained\" + 0.003*\"table\" + 0.003*\"experiment\" + 0.003*\"machine\" + 0.003*\"technique\" + 0.003*\"layer\"\n",
            "\n",
            "Topic #10:\n",
            "0.015*\"word\" + 0.010*\"recognition\" + 0.009*\"training\" + 0.008*\"unit\" + 0.006*\"sequence\" + 0.006*\"speech\" + 0.006*\"feature\" + 0.005*\"representation\" + 0.005*\"context\" + 0.005*\"node\" + 0.005*\"hmm\" + 0.005*\"pattern\" + 0.005*\"character\" + 0.005*\"vector\" + 0.005*\"structure\" + 0.004*\"trained\" + 0.004*\"state\" + 0.004*\"speaker\" + 0.004*\"letter\" + 0.004*\"rule\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuKkIKZGUROT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTKtjsazUR_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e3dc4d4-b951-4ffe-9907-2dfb6b3a8baf"
      },
      "source": [
        "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
        "print('Avg. Coherence Score:', avg_coherence_score)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg. Coherence Score: -1.032899724060749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICzmKIZRUUQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "45de5535-102b-40ae-a374-ff49e5e0a16f"
      },
      "source": [
        "topics_with_wts = [item[0] for item in topics_coherences]\n",
        "print('LDA Topics with Weights')\n",
        "print('='*50)\n",
        "for idx, topic in enumerate(topics_with_wts):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([(term, round(wt, 3)) for wt, term in topic])\n",
        "    print()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LDA Topics with Weights\n",
            "==================================================\n",
            "Topic #1:\n",
            "[('vector', 0.007), ('let', 0.006), ('equation', 0.005), ('bound', 0.005), ('linear', 0.004), ('theorem', 0.004), ('training', 0.004), ('probability', 0.004), ('optimal', 0.004), ('distribution', 0.004), ('solution', 0.004), ('class', 0.004), ('theory', 0.004), ('convergence', 0.004), ('size', 0.004), ('matrix', 0.004), ('approximation', 0.004), ('consider', 0.004), ('rate', 0.004), ('defined', 0.003)]\n",
            "\n",
            "Topic #2:\n",
            "[('distribution', 0.007), ('gaussian', 0.006), ('variable', 0.005), ('vector', 0.005), ('estimate', 0.005), ('prior', 0.005), ('approximation', 0.005), ('mixture', 0.004), ('probability', 0.004), ('density', 0.004), ('sample', 0.004), ('matrix', 0.004), ('bayesian', 0.004), ('structure', 0.004), ('variance', 0.003), ('training', 0.003), ('linear', 0.003), ('unit', 0.003), ('equation', 0.003), ('step', 0.003)]\n",
            "\n",
            "Topic #3:\n",
            "[('training', 0.015), ('classifier', 0.012), ('class', 0.01), ('classification', 0.01), ('pattern', 0.008), ('node', 0.006), ('test', 0.006), ('vector', 0.006), ('training_set', 0.005), ('feature', 0.005), ('chip', 0.004), ('bit', 0.004), ('application', 0.004), ('size', 0.004), ('trained', 0.004), ('table', 0.003), ('experiment', 0.003), ('machine', 0.003), ('technique', 0.003), ('layer', 0.003)]\n",
            "\n",
            "Topic #4:\n",
            "[('cell', 0.021), ('stimulus', 0.011), ('response', 0.01), ('neuron', 0.009), ('unit', 0.007), ('activity', 0.007), ('pattern', 0.006), ('visual', 0.006), ('map', 0.005), ('cortical', 0.005), ('receptive_field', 0.005), ('spike', 0.005), ('layer', 0.005), ('orientation', 0.004), ('spatial', 0.004), ('cortex', 0.004), ('correlation', 0.004), ('effect', 0.003), ('neural', 0.003), ('contrast', 0.003)]\n",
            "\n",
            "Topic #5:\n",
            "[('image', 0.041), ('feature', 0.016), ('object', 0.016), ('pixel', 0.009), ('layer', 0.007), ('view', 0.006), ('face', 0.005), ('recognition', 0.005), ('unit', 0.005), ('representation', 0.005), ('region', 0.004), ('pattern', 0.004), ('training', 0.004), ('task', 0.004), ('location', 0.004), ('edge', 0.004), ('position', 0.004), ('visual', 0.004), ('level', 0.003), ('scene', 0.003)]\n",
            "\n",
            "Topic #6:\n",
            "[('neuron', 0.029), ('circuit', 0.009), ('pattern', 0.008), ('current', 0.007), ('synaptic', 0.007), ('voltage', 0.006), ('cell', 0.005), ('connection', 0.005), ('memory', 0.005), ('neural', 0.005), ('state', 0.005), ('activity', 0.005), ('dynamic', 0.005), ('synapsis', 0.004), ('signal', 0.004), ('synapse', 0.004), ('response', 0.004), ('threshold', 0.004), ('analog', 0.003), ('firing', 0.003)]\n",
            "\n",
            "Topic #7:\n",
            "[('state', 0.023), ('unit', 0.012), ('action', 0.007), ('task', 0.007), ('step', 0.006), ('control', 0.006), ('training', 0.005), ('policy', 0.004), ('sequence', 0.004), ('hidden_unit', 0.004), ('recurrent', 0.004), ('reinforcement_learning', 0.004), ('rule', 0.004), ('net', 0.003), ('architecture', 0.003), ('memory', 0.003), ('environment', 0.003), ('learn', 0.003), ('optimal', 0.003), ('dynamic', 0.003)]\n",
            "\n",
            "Topic #8:\n",
            "[('word', 0.015), ('recognition', 0.01), ('training', 0.009), ('unit', 0.008), ('sequence', 0.006), ('speech', 0.006), ('feature', 0.006), ('representation', 0.005), ('context', 0.005), ('node', 0.005), ('hmm', 0.005), ('pattern', 0.005), ('character', 0.005), ('vector', 0.005), ('structure', 0.005), ('trained', 0.004), ('state', 0.004), ('speaker', 0.004), ('letter', 0.004), ('rule', 0.004)]\n",
            "\n",
            "Topic #9:\n",
            "[('motion', 0.01), ('signal', 0.01), ('control', 0.01), ('target', 0.007), ('visual', 0.006), ('movement', 0.005), ('velocity', 0.005), ('position', 0.005), ('response', 0.005), ('motor', 0.005), ('filter', 0.005), ('frequency', 0.004), ('trajectory', 0.004), ('sound', 0.004), ('subject', 0.004), ('direction', 0.004), ('unit', 0.004), ('auditory', 0.004), ('task', 0.003), ('field', 0.003)]\n",
            "\n",
            "Topic #10:\n",
            "[('signal', 0.011), ('source', 0.009), ('cluster', 0.007), ('component', 0.007), ('code', 0.006), ('channel', 0.006), ('ica', 0.005), ('vector', 0.005), ('clustering', 0.005), ('noise', 0.005), ('representation', 0.005), ('linear', 0.004), ('matrix', 0.004), ('pca', 0.004), ('variable', 0.004), ('eeg', 0.003), ('correlation', 0.003), ('independent_component', 0.003), ('image', 0.003), ('coding', 0.003)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbiSG3sxUqS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "62f645cd-e013-4941-dcee-d55be814960b"
      },
      "source": [
        "\n",
        "print('LDA Topics without Weights')\n",
        "print('='*50)\n",
        "for idx, topic in enumerate(topics_with_wts):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([term for wt, term in topic])\n",
        "    print()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LDA Topics without Weights\n",
            "==================================================\n",
            "Topic #1:\n",
            "['vector', 'let', 'equation', 'bound', 'linear', 'theorem', 'training', 'probability', 'optimal', 'distribution', 'solution', 'class', 'theory', 'convergence', 'size', 'matrix', 'approximation', 'consider', 'rate', 'defined']\n",
            "\n",
            "Topic #2:\n",
            "['distribution', 'gaussian', 'variable', 'vector', 'estimate', 'prior', 'approximation', 'mixture', 'probability', 'density', 'sample', 'matrix', 'bayesian', 'structure', 'variance', 'training', 'linear', 'unit', 'equation', 'step']\n",
            "\n",
            "Topic #3:\n",
            "['training', 'classifier', 'class', 'classification', 'pattern', 'node', 'test', 'vector', 'training_set', 'feature', 'chip', 'bit', 'application', 'size', 'trained', 'table', 'experiment', 'machine', 'technique', 'layer']\n",
            "\n",
            "Topic #4:\n",
            "['cell', 'stimulus', 'response', 'neuron', 'unit', 'activity', 'pattern', 'visual', 'map', 'cortical', 'receptive_field', 'spike', 'layer', 'orientation', 'spatial', 'cortex', 'correlation', 'effect', 'neural', 'contrast']\n",
            "\n",
            "Topic #5:\n",
            "['image', 'feature', 'object', 'pixel', 'layer', 'view', 'face', 'recognition', 'unit', 'representation', 'region', 'pattern', 'training', 'task', 'location', 'edge', 'position', 'visual', 'level', 'scene']\n",
            "\n",
            "Topic #6:\n",
            "['neuron', 'circuit', 'pattern', 'current', 'synaptic', 'voltage', 'cell', 'connection', 'memory', 'neural', 'state', 'activity', 'dynamic', 'synapsis', 'signal', 'synapse', 'response', 'threshold', 'analog', 'firing']\n",
            "\n",
            "Topic #7:\n",
            "['state', 'unit', 'action', 'task', 'step', 'control', 'training', 'policy', 'sequence', 'hidden_unit', 'recurrent', 'reinforcement_learning', 'rule', 'net', 'architecture', 'memory', 'environment', 'learn', 'optimal', 'dynamic']\n",
            "\n",
            "Topic #8:\n",
            "['word', 'recognition', 'training', 'unit', 'sequence', 'speech', 'feature', 'representation', 'context', 'node', 'hmm', 'pattern', 'character', 'vector', 'structure', 'trained', 'state', 'speaker', 'letter', 'rule']\n",
            "\n",
            "Topic #9:\n",
            "['motion', 'signal', 'control', 'target', 'visual', 'movement', 'velocity', 'position', 'response', 'motor', 'filter', 'frequency', 'trajectory', 'sound', 'subject', 'direction', 'unit', 'auditory', 'task', 'field']\n",
            "\n",
            "Topic #10:\n",
            "['signal', 'source', 'cluster', 'component', 'code', 'channel', 'ica', 'vector', 'clustering', 'noise', 'representation', 'linear', 'matrix', 'pca', 'variable', 'eeg', 'correlation', 'independent_component', 'image', 'coding']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwdG5DC-UyAz",
        "colab_type": "text"
      },
      "source": [
        "**Evaluating topic model quality**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwpGZFnZUtIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b94e7617-b472-4665-88f5-ac418c76b62b"
      },
      "source": [
        "\n",
        "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
        "                                                      texts=norm_corpus_bigrams,\n",
        "                                                      dictionary=dictionary, \n",
        "                                                      coherence='c_v')\n",
        "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
        "\n",
        "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
        "                                                         texts=norm_corpus_bigrams,\n",
        "                                                         dictionary=dictionary, \n",
        "                                                         coherence='u_mass')\n",
        "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
        "\n",
        "perplexity = lda_model.log_perplexity(bow_corpus)\n",
        "\n",
        "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
        "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
        "print('Model Perplexity:', perplexity)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg. Coherence Score (Cv): 0.47515264062473844\n",
            "Avg. Coherence Score (UMass): -1.0328997240607491\n",
            "Model Perplexity: -7.794945157875743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyOJL5snWOEB",
        "colab_type": "text"
      },
      "source": [
        "**LDA Models with MALLET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fetq1AvEVv8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ef37e303-23df-4873-d868-72cc6a3670ff"
      },
      "source": [
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "!unzip -q mallet-2.0.8.zip\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-16 14:30:37--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
            "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
            "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16184794 (15M) [application/zip]\n",
            "Saving to: ‘mallet-2.0.8.zip’\n",
            "\n",
            "\rmallet-2.0.8.zip      0%[                    ]       0  --.-KB/s               \rmallet-2.0.8.zip      3%[                    ] 613.37K  2.99MB/s               \rmallet-2.0.8.zip     25%[====>               ]   3.93M  9.83MB/s               \rmallet-2.0.8.zip     47%[========>           ]   7.34M  12.2MB/s               \rmallet-2.0.8.zip     69%[============>       ]  10.73M  13.4MB/s               \rmallet-2.0.8.zip     91%[=================>  ]  14.14M  14.1MB/s               \rmallet-2.0.8.zip    100%[===================>]  15.43M  14.3MB/s    in 1.1s    \n",
            "\n",
            "2020-07-16 14:30:39 (14.3 MB/s) - ‘mallet-2.0.8.zip’ saved [16184794/16184794]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5bsNOyiWS_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b93913e3-0d09-4727-816b-5f07f5176e86"
      },
      "source": [
        "\n",
        "MALLET_PATH = 'mallet-2.0.8/bin/mallet'\n",
        "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus, \n",
        "                                              num_topics=TOTAL_TOPICS, id2word=dictionary,\n",
        "                                              iterations=500, workers=4)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZpHfkLyWge9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "81a748dc-d181-4b77-fcae-d98dca7bd397"
      },
      "source": [
        "cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
        "                                                             texts=norm_corpus_bigrams,\n",
        "                                                             dictionary=dictionary, \n",
        "                                                             coherence='c_v')\n",
        "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
        "\n",
        "umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
        "                                                                texts=norm_corpus_bigrams,\n",
        "                                                                dictionary=dictionary,  \n",
        "                                                                coherence='u_mass')\n",
        "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n",
        "\n",
        "# from STDOUT: <500> LL/token: -8.50105\n",
        "perplexity = -8.50105\n",
        "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
        "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
        "print('Model Perplexity:', perplexity)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg. Coherence Score (Cv): 0.52152005583784\n",
            "Avg. Coherence Score (UMass): -1.032898654364225\n",
            "Model Perplexity: -8.50105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR6U91MHWoTE",
        "colab_type": "text"
      },
      "source": [
        "**LDA Tuning: Finding the optimal number of topics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e2BENSgXOzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def topic_model_coherence_generator(corpus, texts, dictionary, \n",
        "                                    start_topic_count=2, end_topic_count=10, step=1,\n",
        "                                    cpus=1):\n",
        "    \n",
        "    models = []\n",
        "    coherence_scores = []\n",
        "    for topic_nums in tqdm.tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
        "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus,\n",
        "                                                            num_topics=topic_nums, id2word=dictionary,\n",
        "                                                            iterations=500, workers=cpus)\n",
        "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, corpus=corpus, \n",
        "                                                                     texts=texts, dictionary=dictionary, \n",
        "                                                                     coherence='c_v')\n",
        "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
        "        coherence_scores.append(coherence_score)\n",
        "        models.append(mallet_lda_model)\n",
        "    \n",
        "    return models, coherence_scores"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0qmRwTbXlNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7399d1c7-09ad-40f2-9f31-d05d7d09de2a"
      },
      "source": [
        "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
        "                                                               dictionary=dictionary, start_topic_count=2,\n",
        "                                                               end_topic_count=30, step=1, cpus=4)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/29 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "100%|██████████| 29/29 [2:01:05<00:00, 250.53s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLEFSWza6e0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "fb519499-3db6-4d11-8e15-0d4df299992a"
      },
      "source": [
        "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1),\n",
        "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
        "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number of Topics</th>\n",
              "      <th>Coherence Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>29</td>\n",
              "      <td>0.5451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>22</td>\n",
              "      <td>0.5446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>24</td>\n",
              "      <td>0.5410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>23</td>\n",
              "      <td>0.5409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>21</td>\n",
              "      <td>0.5409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>26</td>\n",
              "      <td>0.5401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>20</td>\n",
              "      <td>0.5391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>19</td>\n",
              "      <td>0.5376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>13</td>\n",
              "      <td>0.5370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>18</td>\n",
              "      <td>0.5356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Number of Topics  Coherence Score\n",
              "27                29           0.5451\n",
              "20                22           0.5446\n",
              "22                24           0.5410\n",
              "21                23           0.5409\n",
              "19                21           0.5409\n",
              "24                26           0.5401\n",
              "18                20           0.5391\n",
              "17                19           0.5376\n",
              "11                13           0.5370\n",
              "16                18           0.5356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0HAIoaSfu-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "e0650acb-fc8d-41df-8b9c-e91a4c51d805"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline\n",
        "\n",
        "x_ax = range(2, 31, 1)\n",
        "y_ax = coherence_scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x_ax, y_ax, c='r')\n",
        "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "xl = plt.xlabel('Number of Topics')\n",
        "yl = plt.ylabel('Coherence Score')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnt2dhUNZ1t6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0226f16-0d89-4cc7-f255-f01bccedac91"
      },
      "source": [
        "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 20].index[0]\n",
        "best_lda_model = lda_models[best_model_idx]\n",
        "best_lda_model.num_topics"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNM4wWaPZ5pf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa9c0881-1b6e-45e4-e905-9cced815137d"
      },
      "source": [
        "\n",
        "topics = [[(term, round(wt, 3)) \n",
        "               for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
        "                   for n in range(0, best_lda_model.num_topics)]\n",
        "\n",
        "for idx, topic in enumerate(topics):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([term for term, wt in topic])\n",
        "    print()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1:\n",
            "['word', 'recognition', 'speech', 'training', 'character', 'context', 'sequence', 'hmm', 'letter', 'frame', 'speaker', 'state', 'speech_recognition', 'feature', 'phoneme', 'experiment', 'trained', 'segmentation', 'hybrid', 'probability']\n",
            "\n",
            "Topic #2:\n",
            "['unit', 'layer', 'net', 'hidden_unit', 'training', 'architecture', 'pattern', 'activation', 'trained', 'back_propagation', 'task', 'hidden_layer', 'connection', 'hidden', 'backpropagation', 'learn', 'step', 'epoch', 'simulation', 'required']\n",
            "\n",
            "Topic #3:\n",
            "['circuit', 'chip', 'current', 'analog', 'voltage', 'neuron', 'implementation', 'bit', 'neural', 'design', 'device', 'digital', 'synapse', 'array', 'transistor', 'hardware', 'operation', 'implemented', 'application', 'pulse']\n",
            "\n",
            "Topic #4:\n",
            "['training', 'class', 'classification', 'classifier', 'test', 'training_set', 'pattern', 'feature', 'trained', 'sample', 'table', 'experiment', 'prediction', 'test_set', 'accuracy', 'rbf', 'average', 'size', 'measure', 'generalization']\n",
            "\n",
            "Topic #5:\n",
            "['equation', 'rate', 'eq', 'solution', 'convergence', 'noise', 'gradient', 'vector', 'rule', 'average', 'curve', 'theory', 'limit', 'line', 'matrix', 'optimal', 'eigenvalue', 'correlation', 'generalization_error', 'teacher']\n",
            "\n",
            "Topic #6:\n",
            "['vector', 'sequence', 'code', 'map', 'mapping', 'bit', 'prediction', 'distance', 'region', 'length', 'structure', 'matrix', 'coding', 'time_series', 'dimensional', 'dimension', 'encoding', 'application', 'protein', 'element']\n",
            "\n",
            "Topic #7:\n",
            "['state', 'memory', 'dynamic', 'pattern', 'recurrent', 'neuron', 'attractor', 'matrix', 'capacity', 'module', 'equation', 'hopfield', 'transition', 'fixed_point', 'sequence', 'delay', 'stable', 'type', 'connection', 'associative_memory']\n",
            "\n",
            "Topic #8:\n",
            "['rule', 'representation', 'task', 'structure', 'human', 'connectionist', 'learned', 'language', 'level', 'knowledge', 'symbol', 'category', 'similarity', 'role', 'learn', 'note', 'represented', 'context', 'generalization', 'domain']\n",
            "\n",
            "Topic #9:\n",
            "['image', 'feature', 'object', 'transformation', 'view', 'face', 'representation', 'recognition', 'distance', 'vector', 'pixel', 'pca', 'digit', 'principal_component', 'scale', 'invariant', 'invariance', 'manifold', 'rotation', 'linear']\n",
            "\n",
            "Topic #10:\n",
            "['signal', 'noise', 'filter', 'source', 'channel', 'frequency', 'component', 'sound', 'detection', 'ica', 'auditory', 'temporal', 'correlation', 'phase', 'response', 'amplitude', 'eeg', 'spectral', 'peak', 'independent']\n",
            "\n",
            "Topic #11:\n",
            "['distribution', 'gaussian', 'prior', 'density', 'mixture', 'bayesian', 'estimate', 'approximation', 'likelihood', 'sample', 'component', 'log', 'probability', 'variance', 'em', 'posterior', 'expert', 'step', 'hidden', 'covariance']\n",
            "\n",
            "Topic #12:\n",
            "['neuron', 'spike', 'cell', 'synaptic', 'activity', 'firing', 'response', 'synapsis', 'neural', 'threshold', 'current', 'stimulus', 'effect', 'et_al', 'level', 'frequency', 'oscillator', 'firing_rate', 'temporal', 'constant']\n",
            "\n",
            "Topic #13:\n",
            "['control', 'position', 'trajectory', 'target', 'movement', 'motor', 'hand', 'controller', 'change', 'forward', 'dynamic', 'feedback', 'behavior', 'arm', 'robot', 'field', 'head', 'gain', 'force', 'move']\n",
            "\n",
            "Topic #14:\n",
            "['linear', 'nonlinear', 'optimal', 'kernel', 'estimate', 'regression', 'approximation', 'solution', 'local', 'constraint', 'optimization', 'estimation', 'matrix', 'vector', 'equation', 'quadratic', 'variance', 'minimize', 'technique', 'regularization']\n",
            "\n",
            "Topic #15:\n",
            "['cell', 'stimulus', 'response', 'activity', 'visual', 'pattern', 'map', 'receptive_field', 'cortical', 'cortex', 'layer', 'orientation', 'spatial', 'unit', 'eye', 'neuron', 'connection', 'center', 'brain', 'area']\n",
            "\n",
            "Topic #16:\n",
            "['state', 'action', 'step', 'policy', 'reinforcement_learning', 'task', 'control', 'environment', 'optimal', 'goal', 'trial', 'reward', 'td', 'agent', 'current', 'rl', 'reinforcement', 'transition', 'call', 'iteration']\n",
            "\n",
            "Topic #17:\n",
            "['image', 'motion', 'visual', 'region', 'direction', 'pixel', 'field', 'edge', 'surface', 'local', 'velocity', 'contour', 'location', 'scene', 'light', 'stage', 'vision', 'spatial', 'processing', 'intensity']\n",
            "\n",
            "Topic #18:\n",
            "['node', 'tree', 'search', 'graph', 'solution', 'path', 'size', 'parallel', 'local', 'machine', 'processor', 'constraint', 'run', 'link', 'energy', 'computer', 'block', 'user', 'computation', 'program']\n",
            "\n",
            "Topic #19:\n",
            "['bound', 'class', 'theorem', 'size', 'threshold', 'loss', 'proof', 'probability', 'complexity', 'polynomial', 'theory', 'distribution', 'assume', 'definition', 'approximation', 'linear', 'define', 'defined', 'hypothesis', 'bounded']\n",
            "\n",
            "Topic #20:\n",
            "['variable', 'probability', 'structure', 'cluster', 'level', 'clustering', 'mi', 'part', 'distribution', 'statistical', 'entropy', 'group', 'discrete', 'measure', 'binary', 'hierarchical', 'procedure', 'xi', 'et_al', 'principle']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAyM4ZYBaAG5",
        "colab_type": "text"
      },
      "source": [
        "**Viewing LDA Model topics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ_aKN4jaBf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "3a68bf9f-d49b-4047-8d83-a6e1eea8e754"
      },
      "source": [
        "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
        "                              for topic in topics], \n",
        "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
        "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
        "topics_df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 3</th>\n",
              "      <th>Topic 4</th>\n",
              "      <th>Topic 5</th>\n",
              "      <th>Topic 6</th>\n",
              "      <th>Topic 7</th>\n",
              "      <th>Topic 8</th>\n",
              "      <th>Topic 9</th>\n",
              "      <th>Topic 10</th>\n",
              "      <th>Topic 11</th>\n",
              "      <th>Topic 12</th>\n",
              "      <th>Topic 13</th>\n",
              "      <th>Topic 14</th>\n",
              "      <th>Topic 15</th>\n",
              "      <th>Topic 16</th>\n",
              "      <th>Topic 17</th>\n",
              "      <th>Topic 18</th>\n",
              "      <th>Topic 19</th>\n",
              "      <th>Topic 20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Term1</th>\n",
              "      <td>word</td>\n",
              "      <td>unit</td>\n",
              "      <td>circuit</td>\n",
              "      <td>training</td>\n",
              "      <td>equation</td>\n",
              "      <td>vector</td>\n",
              "      <td>state</td>\n",
              "      <td>rule</td>\n",
              "      <td>image</td>\n",
              "      <td>signal</td>\n",
              "      <td>distribution</td>\n",
              "      <td>neuron</td>\n",
              "      <td>control</td>\n",
              "      <td>linear</td>\n",
              "      <td>cell</td>\n",
              "      <td>state</td>\n",
              "      <td>image</td>\n",
              "      <td>node</td>\n",
              "      <td>bound</td>\n",
              "      <td>variable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term2</th>\n",
              "      <td>recognition</td>\n",
              "      <td>layer</td>\n",
              "      <td>chip</td>\n",
              "      <td>class</td>\n",
              "      <td>rate</td>\n",
              "      <td>sequence</td>\n",
              "      <td>memory</td>\n",
              "      <td>representation</td>\n",
              "      <td>feature</td>\n",
              "      <td>noise</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>spike</td>\n",
              "      <td>position</td>\n",
              "      <td>nonlinear</td>\n",
              "      <td>stimulus</td>\n",
              "      <td>action</td>\n",
              "      <td>motion</td>\n",
              "      <td>tree</td>\n",
              "      <td>class</td>\n",
              "      <td>probability</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term3</th>\n",
              "      <td>speech</td>\n",
              "      <td>net</td>\n",
              "      <td>current</td>\n",
              "      <td>classification</td>\n",
              "      <td>eq</td>\n",
              "      <td>code</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>task</td>\n",
              "      <td>object</td>\n",
              "      <td>filter</td>\n",
              "      <td>prior</td>\n",
              "      <td>cell</td>\n",
              "      <td>trajectory</td>\n",
              "      <td>optimal</td>\n",
              "      <td>response</td>\n",
              "      <td>step</td>\n",
              "      <td>visual</td>\n",
              "      <td>search</td>\n",
              "      <td>theorem</td>\n",
              "      <td>structure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term4</th>\n",
              "      <td>training</td>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>analog</td>\n",
              "      <td>classifier</td>\n",
              "      <td>solution</td>\n",
              "      <td>map</td>\n",
              "      <td>pattern</td>\n",
              "      <td>structure</td>\n",
              "      <td>transformation</td>\n",
              "      <td>source</td>\n",
              "      <td>density</td>\n",
              "      <td>synaptic</td>\n",
              "      <td>target</td>\n",
              "      <td>kernel</td>\n",
              "      <td>activity</td>\n",
              "      <td>policy</td>\n",
              "      <td>region</td>\n",
              "      <td>graph</td>\n",
              "      <td>size</td>\n",
              "      <td>cluster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term5</th>\n",
              "      <td>character</td>\n",
              "      <td>training</td>\n",
              "      <td>voltage</td>\n",
              "      <td>test</td>\n",
              "      <td>convergence</td>\n",
              "      <td>mapping</td>\n",
              "      <td>recurrent</td>\n",
              "      <td>human</td>\n",
              "      <td>view</td>\n",
              "      <td>channel</td>\n",
              "      <td>mixture</td>\n",
              "      <td>activity</td>\n",
              "      <td>movement</td>\n",
              "      <td>estimate</td>\n",
              "      <td>visual</td>\n",
              "      <td>reinforcement_learning</td>\n",
              "      <td>direction</td>\n",
              "      <td>solution</td>\n",
              "      <td>threshold</td>\n",
              "      <td>level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term6</th>\n",
              "      <td>context</td>\n",
              "      <td>architecture</td>\n",
              "      <td>neuron</td>\n",
              "      <td>training_set</td>\n",
              "      <td>noise</td>\n",
              "      <td>bit</td>\n",
              "      <td>neuron</td>\n",
              "      <td>connectionist</td>\n",
              "      <td>face</td>\n",
              "      <td>frequency</td>\n",
              "      <td>bayesian</td>\n",
              "      <td>firing</td>\n",
              "      <td>motor</td>\n",
              "      <td>regression</td>\n",
              "      <td>pattern</td>\n",
              "      <td>task</td>\n",
              "      <td>pixel</td>\n",
              "      <td>path</td>\n",
              "      <td>loss</td>\n",
              "      <td>clustering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term7</th>\n",
              "      <td>sequence</td>\n",
              "      <td>pattern</td>\n",
              "      <td>implementation</td>\n",
              "      <td>pattern</td>\n",
              "      <td>gradient</td>\n",
              "      <td>prediction</td>\n",
              "      <td>attractor</td>\n",
              "      <td>learned</td>\n",
              "      <td>representation</td>\n",
              "      <td>component</td>\n",
              "      <td>estimate</td>\n",
              "      <td>response</td>\n",
              "      <td>hand</td>\n",
              "      <td>approximation</td>\n",
              "      <td>map</td>\n",
              "      <td>control</td>\n",
              "      <td>field</td>\n",
              "      <td>size</td>\n",
              "      <td>proof</td>\n",
              "      <td>mi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term8</th>\n",
              "      <td>hmm</td>\n",
              "      <td>activation</td>\n",
              "      <td>bit</td>\n",
              "      <td>feature</td>\n",
              "      <td>vector</td>\n",
              "      <td>distance</td>\n",
              "      <td>matrix</td>\n",
              "      <td>language</td>\n",
              "      <td>recognition</td>\n",
              "      <td>sound</td>\n",
              "      <td>approximation</td>\n",
              "      <td>synapsis</td>\n",
              "      <td>controller</td>\n",
              "      <td>solution</td>\n",
              "      <td>receptive_field</td>\n",
              "      <td>environment</td>\n",
              "      <td>edge</td>\n",
              "      <td>parallel</td>\n",
              "      <td>probability</td>\n",
              "      <td>part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term9</th>\n",
              "      <td>letter</td>\n",
              "      <td>trained</td>\n",
              "      <td>neural</td>\n",
              "      <td>trained</td>\n",
              "      <td>rule</td>\n",
              "      <td>region</td>\n",
              "      <td>capacity</td>\n",
              "      <td>level</td>\n",
              "      <td>distance</td>\n",
              "      <td>detection</td>\n",
              "      <td>likelihood</td>\n",
              "      <td>neural</td>\n",
              "      <td>change</td>\n",
              "      <td>local</td>\n",
              "      <td>cortical</td>\n",
              "      <td>optimal</td>\n",
              "      <td>surface</td>\n",
              "      <td>local</td>\n",
              "      <td>complexity</td>\n",
              "      <td>distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term10</th>\n",
              "      <td>frame</td>\n",
              "      <td>back_propagation</td>\n",
              "      <td>design</td>\n",
              "      <td>sample</td>\n",
              "      <td>average</td>\n",
              "      <td>length</td>\n",
              "      <td>module</td>\n",
              "      <td>knowledge</td>\n",
              "      <td>vector</td>\n",
              "      <td>ica</td>\n",
              "      <td>sample</td>\n",
              "      <td>threshold</td>\n",
              "      <td>forward</td>\n",
              "      <td>constraint</td>\n",
              "      <td>cortex</td>\n",
              "      <td>goal</td>\n",
              "      <td>local</td>\n",
              "      <td>machine</td>\n",
              "      <td>polynomial</td>\n",
              "      <td>statistical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term11</th>\n",
              "      <td>speaker</td>\n",
              "      <td>task</td>\n",
              "      <td>device</td>\n",
              "      <td>table</td>\n",
              "      <td>curve</td>\n",
              "      <td>structure</td>\n",
              "      <td>equation</td>\n",
              "      <td>symbol</td>\n",
              "      <td>pixel</td>\n",
              "      <td>auditory</td>\n",
              "      <td>component</td>\n",
              "      <td>current</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>optimization</td>\n",
              "      <td>layer</td>\n",
              "      <td>trial</td>\n",
              "      <td>velocity</td>\n",
              "      <td>processor</td>\n",
              "      <td>theory</td>\n",
              "      <td>entropy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term12</th>\n",
              "      <td>state</td>\n",
              "      <td>hidden_layer</td>\n",
              "      <td>digital</td>\n",
              "      <td>experiment</td>\n",
              "      <td>theory</td>\n",
              "      <td>matrix</td>\n",
              "      <td>hopfield</td>\n",
              "      <td>category</td>\n",
              "      <td>pca</td>\n",
              "      <td>temporal</td>\n",
              "      <td>log</td>\n",
              "      <td>stimulus</td>\n",
              "      <td>feedback</td>\n",
              "      <td>estimation</td>\n",
              "      <td>orientation</td>\n",
              "      <td>reward</td>\n",
              "      <td>contour</td>\n",
              "      <td>constraint</td>\n",
              "      <td>distribution</td>\n",
              "      <td>group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term13</th>\n",
              "      <td>speech_recognition</td>\n",
              "      <td>connection</td>\n",
              "      <td>synapse</td>\n",
              "      <td>prediction</td>\n",
              "      <td>limit</td>\n",
              "      <td>coding</td>\n",
              "      <td>transition</td>\n",
              "      <td>similarity</td>\n",
              "      <td>digit</td>\n",
              "      <td>correlation</td>\n",
              "      <td>probability</td>\n",
              "      <td>effect</td>\n",
              "      <td>behavior</td>\n",
              "      <td>matrix</td>\n",
              "      <td>spatial</td>\n",
              "      <td>td</td>\n",
              "      <td>location</td>\n",
              "      <td>run</td>\n",
              "      <td>assume</td>\n",
              "      <td>discrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term14</th>\n",
              "      <td>feature</td>\n",
              "      <td>hidden</td>\n",
              "      <td>array</td>\n",
              "      <td>test_set</td>\n",
              "      <td>line</td>\n",
              "      <td>time_series</td>\n",
              "      <td>fixed_point</td>\n",
              "      <td>role</td>\n",
              "      <td>principal_component</td>\n",
              "      <td>phase</td>\n",
              "      <td>variance</td>\n",
              "      <td>et_al</td>\n",
              "      <td>arm</td>\n",
              "      <td>vector</td>\n",
              "      <td>unit</td>\n",
              "      <td>agent</td>\n",
              "      <td>scene</td>\n",
              "      <td>link</td>\n",
              "      <td>definition</td>\n",
              "      <td>measure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term15</th>\n",
              "      <td>phoneme</td>\n",
              "      <td>backpropagation</td>\n",
              "      <td>transistor</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>matrix</td>\n",
              "      <td>dimensional</td>\n",
              "      <td>sequence</td>\n",
              "      <td>learn</td>\n",
              "      <td>scale</td>\n",
              "      <td>response</td>\n",
              "      <td>em</td>\n",
              "      <td>level</td>\n",
              "      <td>robot</td>\n",
              "      <td>equation</td>\n",
              "      <td>eye</td>\n",
              "      <td>current</td>\n",
              "      <td>light</td>\n",
              "      <td>energy</td>\n",
              "      <td>approximation</td>\n",
              "      <td>binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term16</th>\n",
              "      <td>experiment</td>\n",
              "      <td>learn</td>\n",
              "      <td>hardware</td>\n",
              "      <td>rbf</td>\n",
              "      <td>optimal</td>\n",
              "      <td>dimension</td>\n",
              "      <td>delay</td>\n",
              "      <td>note</td>\n",
              "      <td>invariant</td>\n",
              "      <td>amplitude</td>\n",
              "      <td>posterior</td>\n",
              "      <td>frequency</td>\n",
              "      <td>field</td>\n",
              "      <td>quadratic</td>\n",
              "      <td>neuron</td>\n",
              "      <td>rl</td>\n",
              "      <td>stage</td>\n",
              "      <td>computer</td>\n",
              "      <td>linear</td>\n",
              "      <td>hierarchical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term17</th>\n",
              "      <td>trained</td>\n",
              "      <td>step</td>\n",
              "      <td>operation</td>\n",
              "      <td>average</td>\n",
              "      <td>eigenvalue</td>\n",
              "      <td>encoding</td>\n",
              "      <td>stable</td>\n",
              "      <td>represented</td>\n",
              "      <td>invariance</td>\n",
              "      <td>eeg</td>\n",
              "      <td>expert</td>\n",
              "      <td>oscillator</td>\n",
              "      <td>head</td>\n",
              "      <td>variance</td>\n",
              "      <td>connection</td>\n",
              "      <td>reinforcement</td>\n",
              "      <td>vision</td>\n",
              "      <td>block</td>\n",
              "      <td>define</td>\n",
              "      <td>procedure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term18</th>\n",
              "      <td>segmentation</td>\n",
              "      <td>epoch</td>\n",
              "      <td>implemented</td>\n",
              "      <td>size</td>\n",
              "      <td>correlation</td>\n",
              "      <td>application</td>\n",
              "      <td>type</td>\n",
              "      <td>context</td>\n",
              "      <td>manifold</td>\n",
              "      <td>spectral</td>\n",
              "      <td>step</td>\n",
              "      <td>firing_rate</td>\n",
              "      <td>gain</td>\n",
              "      <td>minimize</td>\n",
              "      <td>center</td>\n",
              "      <td>transition</td>\n",
              "      <td>spatial</td>\n",
              "      <td>user</td>\n",
              "      <td>defined</td>\n",
              "      <td>xi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term19</th>\n",
              "      <td>hybrid</td>\n",
              "      <td>simulation</td>\n",
              "      <td>application</td>\n",
              "      <td>measure</td>\n",
              "      <td>generalization_error</td>\n",
              "      <td>protein</td>\n",
              "      <td>connection</td>\n",
              "      <td>generalization</td>\n",
              "      <td>rotation</td>\n",
              "      <td>peak</td>\n",
              "      <td>hidden</td>\n",
              "      <td>temporal</td>\n",
              "      <td>force</td>\n",
              "      <td>technique</td>\n",
              "      <td>brain</td>\n",
              "      <td>call</td>\n",
              "      <td>processing</td>\n",
              "      <td>computation</td>\n",
              "      <td>hypothesis</td>\n",
              "      <td>et_al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term20</th>\n",
              "      <td>probability</td>\n",
              "      <td>required</td>\n",
              "      <td>pulse</td>\n",
              "      <td>generalization</td>\n",
              "      <td>teacher</td>\n",
              "      <td>element</td>\n",
              "      <td>associative_memory</td>\n",
              "      <td>domain</td>\n",
              "      <td>linear</td>\n",
              "      <td>independent</td>\n",
              "      <td>covariance</td>\n",
              "      <td>constant</td>\n",
              "      <td>move</td>\n",
              "      <td>regularization</td>\n",
              "      <td>area</td>\n",
              "      <td>iteration</td>\n",
              "      <td>intensity</td>\n",
              "      <td>program</td>\n",
              "      <td>bounded</td>\n",
              "      <td>principle</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Topic 1           Topic 2  ...       Topic 19      Topic 20\n",
              "Term1                 word              unit  ...          bound      variable\n",
              "Term2          recognition             layer  ...          class   probability\n",
              "Term3               speech               net  ...        theorem     structure\n",
              "Term4             training       hidden_unit  ...           size       cluster\n",
              "Term5            character          training  ...      threshold         level\n",
              "Term6              context      architecture  ...           loss    clustering\n",
              "Term7             sequence           pattern  ...          proof            mi\n",
              "Term8                  hmm        activation  ...    probability          part\n",
              "Term9               letter           trained  ...     complexity  distribution\n",
              "Term10               frame  back_propagation  ...     polynomial   statistical\n",
              "Term11             speaker              task  ...         theory       entropy\n",
              "Term12               state      hidden_layer  ...   distribution         group\n",
              "Term13  speech_recognition        connection  ...         assume      discrete\n",
              "Term14             feature            hidden  ...     definition       measure\n",
              "Term15             phoneme   backpropagation  ...  approximation        binary\n",
              "Term16          experiment             learn  ...         linear  hierarchical\n",
              "Term17             trained              step  ...         define     procedure\n",
              "Term18        segmentation             epoch  ...        defined            xi\n",
              "Term19              hybrid        simulation  ...     hypothesis         et_al\n",
              "Term20         probability          required  ...        bounded     principle\n",
              "\n",
              "[20 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmIT4PgZaFfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55bc6161-8117-41f8-acc0-bbd3dbecf9f3"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])  \n",
        "                              for topic in topics],\n",
        "                         columns = ['Terms per Topic'],\n",
        "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
        "                         )\n",
        "topics_df"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Terms per Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic1</th>\n",
              "      <td>word, recognition, speech, training, character, context, sequence, hmm, letter, frame, speaker, state, speech_recognition, feature, phoneme, experiment, trained, segmentation, hybrid, probability</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic2</th>\n",
              "      <td>unit, layer, net, hidden_unit, training, architecture, pattern, activation, trained, back_propagation, task, hidden_layer, connection, hidden, backpropagation, learn, step, epoch, simulation, required</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic3</th>\n",
              "      <td>circuit, chip, current, analog, voltage, neuron, implementation, bit, neural, design, device, digital, synapse, array, transistor, hardware, operation, implemented, application, pulse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic4</th>\n",
              "      <td>training, class, classification, classifier, test, training_set, pattern, feature, trained, sample, table, experiment, prediction, test_set, accuracy, rbf, average, size, measure, generalization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic5</th>\n",
              "      <td>equation, rate, eq, solution, convergence, noise, gradient, vector, rule, average, curve, theory, limit, line, matrix, optimal, eigenvalue, correlation, generalization_error, teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic6</th>\n",
              "      <td>vector, sequence, code, map, mapping, bit, prediction, distance, region, length, structure, matrix, coding, time_series, dimensional, dimension, encoding, application, protein, element</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic7</th>\n",
              "      <td>state, memory, dynamic, pattern, recurrent, neuron, attractor, matrix, capacity, module, equation, hopfield, transition, fixed_point, sequence, delay, stable, type, connection, associative_memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic8</th>\n",
              "      <td>rule, representation, task, structure, human, connectionist, learned, language, level, knowledge, symbol, category, similarity, role, learn, note, represented, context, generalization, domain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic9</th>\n",
              "      <td>image, feature, object, transformation, view, face, representation, recognition, distance, vector, pixel, pca, digit, principal_component, scale, invariant, invariance, manifold, rotation, linear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic10</th>\n",
              "      <td>signal, noise, filter, source, channel, frequency, component, sound, detection, ica, auditory, temporal, correlation, phase, response, amplitude, eeg, spectral, peak, independent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic11</th>\n",
              "      <td>distribution, gaussian, prior, density, mixture, bayesian, estimate, approximation, likelihood, sample, component, log, probability, variance, em, posterior, expert, step, hidden, covariance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic12</th>\n",
              "      <td>neuron, spike, cell, synaptic, activity, firing, response, synapsis, neural, threshold, current, stimulus, effect, et_al, level, frequency, oscillator, firing_rate, temporal, constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic13</th>\n",
              "      <td>control, position, trajectory, target, movement, motor, hand, controller, change, forward, dynamic, feedback, behavior, arm, robot, field, head, gain, force, move</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic14</th>\n",
              "      <td>linear, nonlinear, optimal, kernel, estimate, regression, approximation, solution, local, constraint, optimization, estimation, matrix, vector, equation, quadratic, variance, minimize, technique, regularization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic15</th>\n",
              "      <td>cell, stimulus, response, activity, visual, pattern, map, receptive_field, cortical, cortex, layer, orientation, spatial, unit, eye, neuron, connection, center, brain, area</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic16</th>\n",
              "      <td>state, action, step, policy, reinforcement_learning, task, control, environment, optimal, goal, trial, reward, td, agent, current, rl, reinforcement, transition, call, iteration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic17</th>\n",
              "      <td>image, motion, visual, region, direction, pixel, field, edge, surface, local, velocity, contour, location, scene, light, stage, vision, spatial, processing, intensity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic18</th>\n",
              "      <td>node, tree, search, graph, solution, path, size, parallel, local, machine, processor, constraint, run, link, energy, computer, block, user, computation, program</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic19</th>\n",
              "      <td>bound, class, theorem, size, threshold, loss, proof, probability, complexity, polynomial, theory, distribution, assume, definition, approximation, linear, define, defined, hypothesis, bounded</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic20</th>\n",
              "      <td>variable, probability, structure, cluster, level, clustering, mi, part, distribution, statistical, entropy, group, discrete, measure, binary, hierarchical, procedure, xi, et_al, principle</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                            Terms per Topic\n",
              "Topic1   word, recognition, speech, training, character, context, sequence, hmm, letter, frame, speaker, state, speech_recognition, feature, phoneme, experiment, trained, segmentation, hybrid, probability               \n",
              "Topic2   unit, layer, net, hidden_unit, training, architecture, pattern, activation, trained, back_propagation, task, hidden_layer, connection, hidden, backpropagation, learn, step, epoch, simulation, required          \n",
              "Topic3   circuit, chip, current, analog, voltage, neuron, implementation, bit, neural, design, device, digital, synapse, array, transistor, hardware, operation, implemented, application, pulse                           \n",
              "Topic4   training, class, classification, classifier, test, training_set, pattern, feature, trained, sample, table, experiment, prediction, test_set, accuracy, rbf, average, size, measure, generalization                \n",
              "Topic5   equation, rate, eq, solution, convergence, noise, gradient, vector, rule, average, curve, theory, limit, line, matrix, optimal, eigenvalue, correlation, generalization_error, teacher                            \n",
              "Topic6   vector, sequence, code, map, mapping, bit, prediction, distance, region, length, structure, matrix, coding, time_series, dimensional, dimension, encoding, application, protein, element                          \n",
              "Topic7   state, memory, dynamic, pattern, recurrent, neuron, attractor, matrix, capacity, module, equation, hopfield, transition, fixed_point, sequence, delay, stable, type, connection, associative_memory               \n",
              "Topic8   rule, representation, task, structure, human, connectionist, learned, language, level, knowledge, symbol, category, similarity, role, learn, note, represented, context, generalization, domain                   \n",
              "Topic9   image, feature, object, transformation, view, face, representation, recognition, distance, vector, pixel, pca, digit, principal_component, scale, invariant, invariance, manifold, rotation, linear               \n",
              "Topic10  signal, noise, filter, source, channel, frequency, component, sound, detection, ica, auditory, temporal, correlation, phase, response, amplitude, eeg, spectral, peak, independent                                \n",
              "Topic11  distribution, gaussian, prior, density, mixture, bayesian, estimate, approximation, likelihood, sample, component, log, probability, variance, em, posterior, expert, step, hidden, covariance                    \n",
              "Topic12  neuron, spike, cell, synaptic, activity, firing, response, synapsis, neural, threshold, current, stimulus, effect, et_al, level, frequency, oscillator, firing_rate, temporal, constant                           \n",
              "Topic13  control, position, trajectory, target, movement, motor, hand, controller, change, forward, dynamic, feedback, behavior, arm, robot, field, head, gain, force, move                                                \n",
              "Topic14  linear, nonlinear, optimal, kernel, estimate, regression, approximation, solution, local, constraint, optimization, estimation, matrix, vector, equation, quadratic, variance, minimize, technique, regularization\n",
              "Topic15  cell, stimulus, response, activity, visual, pattern, map, receptive_field, cortical, cortex, layer, orientation, spatial, unit, eye, neuron, connection, center, brain, area                                      \n",
              "Topic16  state, action, step, policy, reinforcement_learning, task, control, environment, optimal, goal, trial, reward, td, agent, current, rl, reinforcement, transition, call, iteration                                 \n",
              "Topic17  image, motion, visual, region, direction, pixel, field, edge, surface, local, velocity, contour, location, scene, light, stage, vision, spatial, processing, intensity                                            \n",
              "Topic18  node, tree, search, graph, solution, path, size, parallel, local, machine, processor, constraint, run, link, energy, computer, block, user, computation, program                                                  \n",
              "Topic19  bound, class, theorem, size, threshold, loss, proof, probability, complexity, polynomial, theory, distribution, assume, definition, approximation, linear, define, defined, hypothesis, bounded                   \n",
              "Topic20  variable, probability, structure, cluster, level, clustering, mi, part, distribution, statistical, entropy, group, discrete, measure, binary, hierarchical, procedure, xi, et_al, principle                       "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO9sQL02gNqq",
        "colab_type": "text"
      },
      "source": [
        "**Interpreting Topic Model Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xaHkc-i-8uf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d85b4211-3b82-494a-aeb8-8e44be0f2d12"
      },
      "source": [
        "tm_results = best_lda_model[bow_corpus]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIfyGS3GgSD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d8f301e6-363c-48cd-b892-0fdf4dd8c7f2"
      },
      "source": [
        "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] \n",
        "                     for topics in tm_results]\n",
        "corpus_topics[:5]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(11, 0.5225239284228048),\n",
              " (17, 0.4994752308984047),\n",
              " (0, 0.28646626078132925),\n",
              " (14, 0.2635732323232324),\n",
              " (9, 0.2552643369175628)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp4Pm93xgV48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_topic_df = pd.DataFrame()\n",
        "corpus_topic_df['Document'] = range(0, len(papers))\n",
        "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
        "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
        "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
        "corpus_topic_df['Paper'] = papers"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyvIIet6gaOT",
        "colab_type": "text"
      },
      "source": [
        "**Dominant Topics in Specific Research Papers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEQ7V3qBgYtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1b1ec36-1ae4-4983-b551-e2036695561e"
      },
      "source": [
        "corpus_topic_df.groupby('Dominant Topic').apply(lambda topic_set: (topic_set.sort_values(by=['Contribution %'], \n",
        "                                                                                         ascending=False)\n",
        "                                                                             .iloc[0]))\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>Contribution %</th>\n",
              "      <th>Topic Desc</th>\n",
              "      <th>Paper</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>687</td>\n",
              "      <td>1</td>\n",
              "      <td>70.91</td>\n",
              "      <td>word, recognition, speech, training, character, context, sequence, hmm, letter, frame, speaker, state, speech_recognition, feature, phoneme, experiment, trained, segmentation, hybrid, probability</td>\n",
              "      <td>Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>250</td>\n",
              "      <td>2</td>\n",
              "      <td>58.66</td>\n",
              "      <td>unit, layer, net, hidden_unit, training, architecture, pattern, activation, trained, back_propagation, task, hidden_layer, connection, hidden, backpropagation, learn, step, epoch, simulation, requ...</td>\n",
              "      <td>524 Fahlman and Lebiere \\nThe Cascade-Correlation Learning Architecture \\nScott E. Fahlman and Christian Lebiere \\nSchool of Computer Science \\nCarnegie-Mellon University \\nPittsburgh, PA 15213 \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>918</td>\n",
              "      <td>3</td>\n",
              "      <td>69.89</td>\n",
              "      <td>circuit, chip, current, analog, voltage, neuron, implementation, bit, neural, design, device, digital, synapse, array, transistor, hardware, operation, implemented, application, pulse</td>\n",
              "      <td>Single Transistor Learning Synapses \\nPaul Hasler, Chris Diorio, Bradley A. Minch, Carver Mead \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\n(SlS) 95- 2S12 \\npaul@hobiecat.pcmp.calt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>633</td>\n",
              "      <td>4</td>\n",
              "      <td>69.60</td>\n",
              "      <td>training, class, classification, classifier, test, training_set, pattern, feature, trained, sample, table, experiment, prediction, test_set, accuracy, rbf, average, size, measure, generalization</td>\n",
              "      <td>A Boundary Hunting Radial Basis Function \\nClassifier Which Allocates Centers \\nConstructively \\nEric I. Chang and Richard P. Lippmann \\nMIT Lincoln Laboratory \\nLexington, MA 02173-0073, USA \\nAb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1587</td>\n",
              "      <td>5</td>\n",
              "      <td>69.87</td>\n",
              "      <td>equation, rate, eq, solution, convergence, noise, gradient, vector, rule, average, curve, theory, limit, line, matrix, optimal, eigenvalue, correlation, generalization_error, teacher</td>\n",
              "      <td>Dynamics of Supervised Learning with \\nRestricted Training Sets \\nA.C.C. Coolen \\nDept of Mathematics \\nKing's College London \\nStrand, London WC2R 2LS, UK \\ntcoolen @mth.kcl.ac.uk \\nD. Saad \\nNeu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1276</td>\n",
              "      <td>6</td>\n",
              "      <td>46.79</td>\n",
              "      <td>vector, sequence, code, map, mapping, bit, prediction, distance, region, length, structure, matrix, coding, time_series, dimensional, dimension, encoding, application, protein, element</td>\n",
              "      <td>Genetic Algorithms and Explicit Search Statistics \\nShumeet Baluja \\nbaluja@cs.cmu.edu \\nJustsystem Pittsburgh Research Center &amp; \\nSchool of Computer Science, Carnegie Mellon University \\nAbstract...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>58</td>\n",
              "      <td>7</td>\n",
              "      <td>53.77</td>\n",
              "      <td>state, memory, dynamic, pattern, recurrent, neuron, attractor, matrix, capacity, module, equation, hopfield, transition, fixed_point, sequence, delay, stable, type, connection, associative_memory</td>\n",
              "      <td>524 \\nBASINS OF ATTRACTION FOR \\nELECTRONIC NEURAL NETWORKS \\nC. M. Marcus \\nR. M. Westervelt \\nDivision of Applied Sciences and Department of Physics \\nHarvard University, Cambridge, MA 02138 \\nA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>669</td>\n",
              "      <td>8</td>\n",
              "      <td>62.66</td>\n",
              "      <td>rule, representation, task, structure, human, connectionist, learned, language, level, knowledge, symbol, category, similarity, role, learn, note, represented, context, generalization, domain</td>\n",
              "      <td>Analogy--Watershed or Waterloo? \\nStructural alignment and the development of \\nconnectionist models of analogy \\nDedre Gentner Arthur B. Markman \\nDepartment of Psychology Department of Psycholog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>447</td>\n",
              "      <td>9</td>\n",
              "      <td>54.39</td>\n",
              "      <td>image, feature, object, transformation, view, face, representation, recognition, distance, vector, pixel, pca, digit, principal_component, scale, invariant, invariance, manifold, rotation, linear</td>\n",
              "      <td>Linear Operator for Object Recognition \\nPonen Basil Shimon Ullman* \\nM.I.T. Artificial Intelligence Laboratory \\nand Department of Brain and Cognitive Science \\n545 Technology Square \\nCambridge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1374</td>\n",
              "      <td>10</td>\n",
              "      <td>62.66</td>\n",
              "      <td>signal, noise, filter, source, channel, frequency, component, sound, detection, ica, auditory, temporal, correlation, phase, response, amplitude, eeg, spectral, peak, independent</td>\n",
              "      <td>Extended ICA Removes Artifacts from \\nElectroencephalographic Recordings \\nTzyy-Ping Jung , Colin Humphries , Te-Won Lee , Scott Makeig 2'3, \\nMartin J. McKeown , Vicente Iragui 3, Terrence J....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1427</td>\n",
              "      <td>11</td>\n",
              "      <td>65.73</td>\n",
              "      <td>distribution, gaussian, prior, density, mixture, bayesian, estimate, approximation, likelihood, sample, component, log, probability, variance, em, posterior, expert, step, hidden, covariance</td>\n",
              "      <td>Regression with Input-dependent Noise: \\nA Gaussian Process Treatment \\nPaul W. Goldberg \\nDepartment of Computer Science \\nUniversity of Warwick \\nCoventry, CV4 7AL, UK \\npgdcs. arick. ac. uk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>281</td>\n",
              "      <td>12</td>\n",
              "      <td>76.49</td>\n",
              "      <td>neuron, spike, cell, synaptic, activity, firing, response, synapsis, neural, threshold, current, stimulus, effect, et_al, level, frequency, oscillator, firing_rate, temporal, constant</td>\n",
              "      <td>A Systematic Study of the Input/Output Properties 149 \\nA Systematic Study of the Input/Output Properties \\nof a 2 Compartment Model Neuron \\nWith Active Membranes \\nPaul Rhodes \\nUniversity of Ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>380</td>\n",
              "      <td>13</td>\n",
              "      <td>72.95</td>\n",
              "      <td>control, position, trajectory, target, movement, motor, hand, controller, change, forward, dynamic, feedback, behavior, arm, robot, field, head, gain, force, move</td>\n",
              "      <td>Learning Trajectory and Force Control \\nof an Artificial Muscle Arm \\nby Parallel-hierarchical Neural Network Model \\nMasazumi Katayama Mitsuo Kawato \\nCognitive Processes Department \\nATR Auditor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1151</td>\n",
              "      <td>14</td>\n",
              "      <td>56.14</td>\n",
              "      <td>linear, nonlinear, optimal, kernel, estimate, regression, approximation, solution, local, constraint, optimization, estimation, matrix, vector, equation, quadratic, variance, minimize, technique, ...</td>\n",
              "      <td>Support Vector Method for Function \\nApproximation, Regression Estimation, \\nand Signal Processing' \\nVladimir Vapnik \\nAT&amp;T Research \\n101 Crawfords Corner \\nHolmdel, NJ 07733 \\nvlad@research.att...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>803</td>\n",
              "      <td>15</td>\n",
              "      <td>67.89</td>\n",
              "      <td>cell, stimulus, response, activity, visual, pattern, map, receptive_field, cortical, cortex, layer, orientation, spatial, unit, eye, neuron, connection, center, brain, area</td>\n",
              "      <td>Development of Orientation and Ocular \\nDominance Columns in Infant Macaques \\nKlaus Obermayer \\nHoward Hughes Medical Institute \\nSMk-Institute \\nLa Jolla, CA 92037 \\nLynne Kiorpes \\nCenter for N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1549</td>\n",
              "      <td>16</td>\n",
              "      <td>74.08</td>\n",
              "      <td>state, action, step, policy, reinforcement_learning, task, control, environment, optimal, goal, trial, reward, td, agent, current, rl, reinforcement, transition, call, iteration</td>\n",
              "      <td>The effect of eligibility traces on finding optimal memoryless \\npolicies in partially observable Markov decision processes \\nJohn Loch \\nDepartment of Computer Science \\nUniversity of Colorado \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>183</td>\n",
              "      <td>17</td>\n",
              "      <td>57.32</td>\n",
              "      <td>image, motion, visual, region, direction, pixel, field, edge, surface, local, velocity, contour, location, scene, light, stage, vision, spatial, processing, intensity</td>\n",
              "      <td>297 \\nA NETWORK FOR IMAGE SEGMENTATION \\nUSING COLOR \\nAnya Hurlbert and Tomaso Poggio \\nCenter for Biological Information Processing at Whitaker College \\nDepartment of Brain and Cognitive Scienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>80</td>\n",
              "      <td>18</td>\n",
              "      <td>55.27</td>\n",
              "      <td>node, tree, search, graph, solution, path, size, parallel, local, machine, processor, constraint, run, link, energy, computer, block, user, computation, program</td>\n",
              "      <td>804 \\nINTRODUCTION TO A SYSTEM FOR IMPLEMENTING NEURAL NET \\nCONNECTIONS ON SIMD ARCHITECTURES \\nSherryl Tomboulian \\nInstitute for Computer Applications in Science and Engineering \\nNASA Langley ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>443</td>\n",
              "      <td>19</td>\n",
              "      <td>83.81</td>\n",
              "      <td>bound, class, theorem, size, threshold, loss, proof, probability, complexity, polynomial, theory, distribution, assume, definition, approximation, linear, define, defined, hypothesis, bounded</td>\n",
              "      <td>Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1464</td>\n",
              "      <td>20</td>\n",
              "      <td>50.78</td>\n",
              "      <td>variable, probability, structure, cluster, level, clustering, mi, part, distribution, statistical, entropy, group, discrete, measure, binary, hierarchical, procedure, xi, et_al, principle</td>\n",
              "      <td>Visualizing Group Structure* \\nMarcus Held, Jan Puzicha, and Joachim M. Buhmann \\nInstitut fiir Informatik III, \\nRSmerstrafie 164, D-53117 Bonn, Germany \\nemail: {heldianib}.cs.uni-bonn.de, \\nW...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Document  ...                                                                                                                                                                                                    Paper\n",
              "Dominant Topic            ...                                                                                                                                                                                                         \n",
              "1                    687  ...  Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...\n",
              "2                    250  ...  524 Fahlman and Lebiere \\nThe Cascade-Correlation Learning Architecture \\nScott E. Fahlman and Christian Lebiere \\nSchool of Computer Science \\nCarnegie-Mellon University \\nPittsburgh, PA 15213 \\n...\n",
              "3                    918  ...  Single Transistor Learning Synapses \\nPaul Hasler, Chris Diorio, Bradley A. Minch, Carver Mead \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\n(SlS) 95- 2S12 \\npaul@hobiecat.pcmp.calt...\n",
              "4                    633  ...  A Boundary Hunting Radial Basis Function \\nClassifier Which Allocates Centers \\nConstructively \\nEric I. Chang and Richard P. Lippmann \\nMIT Lincoln Laboratory \\nLexington, MA 02173-0073, USA \\nAb...\n",
              "5                   1587  ...  Dynamics of Supervised Learning with \\nRestricted Training Sets \\nA.C.C. Coolen \\nDept of Mathematics \\nKing's College London \\nStrand, London WC2R 2LS, UK \\ntcoolen @mth.kcl.ac.uk \\nD. Saad \\nNeu...\n",
              "6                   1276  ...  Genetic Algorithms and Explicit Search Statistics \\nShumeet Baluja \\nbaluja@cs.cmu.edu \\nJustsystem Pittsburgh Research Center & \\nSchool of Computer Science, Carnegie Mellon University \\nAbstract...\n",
              "7                     58  ...  524 \\nBASINS OF ATTRACTION FOR \\nELECTRONIC NEURAL NETWORKS \\nC. M. Marcus \\nR. M. Westervelt \\nDivision of Applied Sciences and Department of Physics \\nHarvard University, Cambridge, MA 02138 \\nA...\n",
              "8                    669  ...  Analogy--Watershed or Waterloo? \\nStructural alignment and the development of \\nconnectionist models of analogy \\nDedre Gentner Arthur B. Markman \\nDepartment of Psychology Department of Psycholog...\n",
              "9                    447  ...  Linear Operator for Object Recognition \\nPonen Basil Shimon Ullman* \\nM.I.T. Artificial Intelligence Laboratory \\nand Department of Brain and Cognitive Science \\n545 Technology Square \\nCambridge...\n",
              "10                  1374  ...  Extended ICA Removes Artifacts from \\nElectroencephalographic Recordings \\nTzyy-Ping Jung , Colin Humphries , Te-Won Lee , Scott Makeig 2'3, \\nMartin J. McKeown , Vicente Iragui 3, Terrence J....\n",
              "11                  1427  ...  Regression with Input-dependent Noise: \\nA Gaussian Process Treatment \\nPaul W. Goldberg \\nDepartment of Computer Science \\nUniversity of Warwick \\nCoventry, CV4 7AL, UK \\npgdcs. arick. ac. uk...\n",
              "12                   281  ...  A Systematic Study of the Input/Output Properties 149 \\nA Systematic Study of the Input/Output Properties \\nof a 2 Compartment Model Neuron \\nWith Active Membranes \\nPaul Rhodes \\nUniversity of Ca...\n",
              "13                   380  ...  Learning Trajectory and Force Control \\nof an Artificial Muscle Arm \\nby Parallel-hierarchical Neural Network Model \\nMasazumi Katayama Mitsuo Kawato \\nCognitive Processes Department \\nATR Auditor...\n",
              "14                  1151  ...  Support Vector Method for Function \\nApproximation, Regression Estimation, \\nand Signal Processing' \\nVladimir Vapnik \\nAT&T Research \\n101 Crawfords Corner \\nHolmdel, NJ 07733 \\nvlad@research.att...\n",
              "15                   803  ...  Development of Orientation and Ocular \\nDominance Columns in Infant Macaques \\nKlaus Obermayer \\nHoward Hughes Medical Institute \\nSMk-Institute \\nLa Jolla, CA 92037 \\nLynne Kiorpes \\nCenter for N...\n",
              "16                  1549  ...  The effect of eligibility traces on finding optimal memoryless \\npolicies in partially observable Markov decision processes \\nJohn Loch \\nDepartment of Computer Science \\nUniversity of Colorado \\n...\n",
              "17                   183  ...  297 \\nA NETWORK FOR IMAGE SEGMENTATION \\nUSING COLOR \\nAnya Hurlbert and Tomaso Poggio \\nCenter for Biological Information Processing at Whitaker College \\nDepartment of Brain and Cognitive Scienc...\n",
              "18                    80  ...  804 \\nINTRODUCTION TO A SYSTEM FOR IMPLEMENTING NEURAL NET \\nCONNECTIONS ON SIMD ARCHITECTURES \\nSherryl Tomboulian \\nInstitute for Computer Applications in Science and Engineering \\nNASA Langley ...\n",
              "19                   443  ...  Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...\n",
              "20                  1464  ...  Visualizing Group Structure* \\nMarcus Held, Jan Puzicha, and Joachim M. Buhmann \\nInstitut fiir Informatik III, \\nRSmerstrafie 164, D-53117 Bonn, Germany \\nemail: {heldianib}.cs.uni-bonn.de, \\nW...\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv6-4lgRgd39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}